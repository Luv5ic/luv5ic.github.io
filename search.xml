<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>MySQL常用函数总结</title>
    <url>/2021-01-07-MySQL%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="开窗函数"><a href="#开窗函数" class="headerlink" title="开窗函数"></a>开窗函数</h1><p><em>注：<strong>hive</strong>、<strong>oracle</strong>提供开窗函数，<strong>mysql8之前版本</strong>不提供</em>，<em>但Oracle发布的 <strong>MySQL 8.0</strong>版本支持窗口函数（over）和公用表表达式（with）这两个重要的功能！</em></p>
<p>开窗函数是在满足某种条件的记录集合上执行的特殊函数，对于每条记录都要在此窗口内执行函数。函数可分为静态窗口函数和动态窗口函数。</p>
<ul>
<li>静态窗口函数：随着记录不同，窗口大小都是固定的</li>
<li>动态窗口函数：不同的记录对应着不同的窗口。</li>
</ul>
<p>开窗函数的本质还是聚合运算，只不过更具灵活性，它对数据的每一行，都使用与该行相关的行进行计算并返回计算结果。</p>
<p><strong>语法</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">开窗函数名([<span class="operator">&lt;</span>字段名<span class="operator">&gt;</span>]) <span class="keyword">over</span>([<span class="keyword">partition</span> <span class="keyword">by</span> <span class="operator">&lt;</span>分组字段<span class="operator">&gt;</span>] [<span class="keyword">order</span> <span class="keyword">by</span> <span class="operator">&lt;</span>排序字段<span class="operator">&gt;</span> [<span class="keyword">desc</span>]] [<span class="operator">&lt;</span></span><br><span class="line">滑动窗口<span class="operator">&gt;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 比如“排序”</span></span><br><span class="line"><span class="built_in">row_number</span>(),<span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> <span class="type">date</span> <span class="keyword">order</span> <span class="keyword">by</span> id <span class="keyword">desc</span>)</span><br></pre></td></tr></table></figure>
<p>开窗函数的一个概念是当前行，当前行属于某个窗口，窗口由<strong>over关键字</strong>来指定函数执行的窗口范围，<br>如果后面括号中什么都不写，则意味着窗口包含满足where条件的所有行，开窗函数基于所有行进行计算；如果不为空，则有三个参数来设置窗口：</p>
<ul>
<li>partition by子句：按照指定字段进行分区，两个分区由边界分隔，开窗函数在不同的分区内分别执行，在跨越分区边界时重新初始化。</li>
<li>order by子句：按照指定字段进行排序，开窗函数将按照排序后的记录顺序进行编号。可以和<br>partition by子句配合使用，也可以单独使用。</li>
<li>frame子句：当前分区的一个子集，用来定义子集的规则，通常用来作为滑动窗口使用。</li>
</ul>
<p>对于滑动窗口的范围指定，通常使用 between frame_start and frame_end 语法来表示行范围，frame_start和frame_end可以支持如下关键字，来确定不同的动态行记录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">current row 边界是当前行，一般和其他范围关键字一起使用</span><br><span class="line">unbounded preceding 边界是分区中的第一行</span><br><span class="line">unbounded following 边界是分区中的最后一行</span><br><span class="line">expr preceding 边界是当前行减去expr的值</span><br><span class="line">expr following 边界是当前行加上expr的值</span><br></pre></td></tr></table></figure>
<p>比如，下面都是合法的范围：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> preceding <span class="keyword">and</span> <span class="number">1</span> following 窗口范围是分区中的当前行、前一行、后一行一共三行记录。</span><br><span class="line"><span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> preceding <span class="keyword">and</span> <span class="keyword">current</span> <span class="type">row</span> 窗口范围是分区中的前一行、当前行一共两行记录。</span><br><span class="line"><span class="keyword">rows</span> <span class="keyword">between</span> <span class="keyword">current</span> <span class="type">row</span> <span class="keyword">and</span> <span class="number">1</span> following 窗口范围是分区中的当前行、后一行一共两行记录。</span><br><span class="line"><span class="keyword">rows</span> unbounded preceding 窗口范围是分区中的第一行到当前行。</span><br><span class="line"><span class="keyword">rows</span> <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> <span class="keyword">current</span> <span class="type">row</span> 窗口范围是分区中的第一行到当前行。</span><br><span class="line"><span class="keyword">rows</span> <span class="keyword">between</span> <span class="keyword">current</span> <span class="type">row</span> <span class="keyword">and</span> unbounded following 窗口范围是分区中的当前行到最后一行。</span><br><span class="line"><span class="keyword">rows</span> <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> unbounded following 窗口范围是当前分区中所有行。</span><br></pre></td></tr></table></figure>
<h2 id="动态窗口函数"><a href="#动态窗口函数" class="headerlink" title="动态窗口函数"></a>动态窗口函数</h2><p>first_value() / last_value() / nth_value()/聚合函数用于开窗</p>
<ul>
<li>如没有指定排序和滑动窗口范围，默认计算的是分区内的所有记录。</li>
<li>指定分区和排序后，如没有指定滑动窗口范围，默认计算的是分区内的第一行到当前行。</li>
</ul>
<h3 id="FIRST-VALUE-和-LAST-VALUE函数"><a href="#FIRST-VALUE-和-LAST-VALUE函数" class="headerlink" title="FIRST_VALUE 和 LAST_VALUE函数"></a>FIRST_VALUE 和 LAST_VALUE函数</h3><p><code>FIRST_VALUE</code> 取分组内排序后，截止到当前行，第一个值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT cookieid,createtime,pv,</span><br><span class="line">ROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY createtime) AS rn,</span><br><span class="line">FIRST_VALUE(pv) OVER(PARTITION BY cookieid ORDER BY createtime) AS first  </span><br><span class="line">FROM test1;</span><br></pre></td></tr></table></figure>
<p><strong>LAST_VALUE 函数则相反：</strong><br><code>LAST_VALUE</code> 取分组内排序后，截止到当前行，最后一个值</p>
<hr>
<h2 id="静态窗口函数"><a href="#静态窗口函数" class="headerlink" title="静态窗口函数"></a>静态窗口函数</h2><p>row_number() / rank() / dense_rank() / percent_rank() / cume_dist()/lag() /<br>lead() / ntile()</p>
<ul>
<li>不管是否指定滑动窗口范围，窗口都是固定的，所以指定的滑动窗口范围无效。</li>
</ul>
<p>开窗函数和普通聚合函数的区别：</p>
<ul>
<li>聚合函数是将多条记录聚合为一条；而开窗函数是每条记录都会执行，有几条记录执行完还是几条。</li>
<li>聚合函数也可以用于开窗函数中。</li>
</ul>
<h3 id="排序函数"><a href="#排序函数" class="headerlink" title="排序函数"></a>排序函数</h3><ul>
<li>rank()：重复间断的组内排序，例如 1，1，3，4，4，6</li>
<li>dense_rank()：重复不间断的组内排序，例如 1，1，2，2，3</li>
<li>row_number()：不重复不间断的组内排序，例如 1，2，3，4，5</li>
</ul>
<h3 id="cume-dist"><a href="#cume-dist" class="headerlink" title="cume_dist()"></a>cume_dist()</h3><p><em>注：不允许在 CUME_DIST 函数中使用组合排序键（RANGE,ROWS）</em></p>
<p><code>cume_dist</code> 计算某个值在一组行中的相对位置</p>
<p>以下示例返回一个包含居住在 California 的职员的<strong>薪水累计分布的结果集</strong>。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> DepartmentID, Surname, Salary,</span><br><span class="line"><span class="built_in">CUME_DIST</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> DepartmentID <span class="keyword">ORDER</span> <span class="keyword">BY</span> Salary <span class="keyword">DESC</span>) &quot;Rank&quot; </span><br><span class="line"><span class="keyword">FROM</span> Employees  </span><br><span class="line"><span class="keyword">WHERE</span> State <span class="keyword">IN</span> (<span class="string">&#x27;CA&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>以下是该结果集：</p>
<table>
<thead>
<tr>
<th>DepartmentID</th>
<th>Surname</th>
<th>Salary</th>
<th>Rank</th>
</tr>
</thead>
<tbody><tr>
<td>200</td>
<td>Savarino</td>
<td>72300.000</td>
<td>0.333333333333333</td>
</tr>
<tr>
<td>200</td>
<td>Clark</td>
<td>45000.000</td>
<td>0.666666666666667</td>
</tr>
<tr>
<td>200</td>
<td>Overbey</td>
<td>39300.000</td>
<td>1</td>
</tr>
</tbody></table>
<p>也就是说，薪水小于等于72300的人，占整个分组的0.33；薪水小于等于45000的人，占整个分组的0.66。</p>
<h3 id="PERCENT-RANK-函数"><a href="#PERCENT-RANK-函数" class="headerlink" title="PERCENT_RANK 函数"></a>PERCENT_RANK 函数</h3><p>与 PERCENT 函数类似，PERCENT_RANK 函数为窗口的 ORDER BY 子句所指定列中的值返回秩，但以介于 0 和 1 之间的小数形式表示，计算方法为 (分组内当前行的RANK值-1) / (分组内总行数-1)</p>
<p>随着窗口在输入行中向下移动，会计算在窗口的 ORDER BY 子句中所指定的表达式的秩。当 ORDER BY 子句包括多个表达式时，若第一个表达式与相邻行具有相同值，则第二个及后续表达式将用于区分并列情况。NULL 值排在任何其它值的前面（在升序序列中）。</p>
<p><strong>示例 1</strong></p>
<p>以下示例返回按性别显示 New York 雇员薪水排位的结果集。该结果使用百分比数按降序列出排位并按性别分区。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> DepartmentID, Surname, Salary, Sex,    <span class="built_in">PERCENT_RANK</span>( ) <span class="keyword">OVER</span> ( <span class="keyword">PARTITION</span> <span class="keyword">BY</span> Sex      <span class="keyword">ORDER</span> <span class="keyword">BY</span> Salary <span class="keyword">DESC</span> ) <span class="keyword">AS</span> PctRank  <span class="keyword">FROM</span> Employees   <span class="keyword">WHERE</span> State <span class="keyword">IN</span> ( <span class="string">&#x27;NY&#x27;</span> );</span><br></pre></td></tr></table></figure>
<p>此查询会返回以下结果：</p>
<table>
<thead>
<tr>
<th></th>
<th>DepartmentID</th>
<th>Surname</th>
<th>Salary</th>
<th>Sex</th>
<th>PctRank</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>200</td>
<td>Martel</td>
<td>55700.000</td>
<td>M</td>
<td>0.0</td>
</tr>
<tr>
<td>2</td>
<td>100</td>
<td>Guevara</td>
<td>42998.000</td>
<td>M</td>
<td>0.333333333</td>
</tr>
<tr>
<td>3</td>
<td>100</td>
<td>Soo</td>
<td>39075.000</td>
<td>M</td>
<td>0.666666667</td>
</tr>
<tr>
<td>4</td>
<td>400</td>
<td>Ahmed</td>
<td>34992.000</td>
<td>M</td>
<td>1.0</td>
</tr>
<tr>
<td>5</td>
<td>300</td>
<td>Davidson</td>
<td>57090.000</td>
<td>F</td>
<td>0.0</td>
</tr>
<tr>
<td>6</td>
<td>400</td>
<td>Blaikie</td>
<td>54900.000</td>
<td>F</td>
<td>0.333333333</td>
</tr>
<tr>
<td>7</td>
<td>100</td>
<td>Whitney</td>
<td>45700.000</td>
<td>F</td>
<td>0.666666667</td>
</tr>
<tr>
<td>8</td>
<td>400</td>
<td>Wetherby</td>
<td>35745.000</td>
<td>F</td>
<td>1.0</td>
</tr>
</tbody></table>
<p>由于按性别 (Sex) 划分输入，所以分别对男雇员和女雇员执行 PERCENT_RANK 计算。</p>
<p><strong>示例 2</strong></p>
<p>以下示例返回 Utah 和 Arizona 的一些女雇员的列表并根据薪水以降序顺序排列她们。这里的 PERCENT_RANK 函数用于以降序顺序提供累计总数。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Surname, Salary,      <span class="built_in">PERCENT_RANK</span> ( ) <span class="keyword">OVER</span> ( <span class="keyword">ORDER</span> <span class="keyword">BY</span> Salary <span class="keyword">DESC</span> ) &quot;Rank&quot;     <span class="keyword">FROM</span> Employees  <span class="keyword">WHERE</span> State <span class="keyword">IN</span> ( <span class="string">&#x27;UT&#x27;</span>, <span class="string">&#x27;AZ&#x27;</span> ) <span class="keyword">AND</span> Sex <span class="keyword">IN</span> ( <span class="string">&#x27;F&#x27;</span> );</span><br></pre></td></tr></table></figure>
<p>此查询会返回以下结果：</p>
<table>
<thead>
<tr>
<th></th>
<th>Surname</th>
<th>Salary</th>
<th>Rank</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Shishov</td>
<td>72995.00</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>Jordan</td>
<td>51432.00</td>
<td>0.25</td>
</tr>
<tr>
<td>3</td>
<td>Hildebrand</td>
<td>45829.00</td>
<td>0.5</td>
</tr>
<tr>
<td>4</td>
<td>Bigelow</td>
<td>31200.00</td>
<td>0.75</td>
</tr>
<tr>
<td>5</td>
<td>Bertrand</td>
<td>29800.00</td>
<td>1</td>
</tr>
</tbody></table>
<p><strong>使用 PERCENT_RANK 查找最高和最低百分点</strong></p>
<p>在以下示例中，查询会返回其薪水在数据集的最高的五个百分点之内的男雇员。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span>  </span><br><span class="line"><span class="keyword">FROM</span>  ( <span class="keyword">SELECT</span> Surname, Salary,</span><br><span class="line">       <span class="built_in">PERCENT_RANK</span> ( ) <span class="keyword">OVER</span> ( <span class="keyword">ORDER</span> <span class="keyword">BY</span> Salary <span class="keyword">DESC</span> ) &quot;Rank&quot;     </span><br><span class="line">       <span class="keyword">FROM</span> Employees  </span><br><span class="line">       <span class="keyword">WHERE</span> Sex <span class="keyword">IN</span> ( <span class="string">&#x27;M&#x27;</span> )  ) </span><br><span class="line">       <span class="keyword">AS</span> DerivedTable ( Surname, Salary, <span class="keyword">Percent</span> ) </span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">Percent</span> <span class="operator">&lt;</span> <span class="number">0.05</span>;</span><br></pre></td></tr></table></figure>
<p>此查询会返回以下结果：</p>
<table>
<thead>
<tr>
<th></th>
<th>Surname</th>
<th>Salary</th>
<th>Percent</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Scott</td>
<td>96300.00</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>Sheffield</td>
<td>87900.00</td>
<td>0.025</td>
</tr>
<tr>
<td>3</td>
<td>Lull</td>
<td>87900.00</td>
<td>0.025</td>
</tr>
</tbody></table>
<h3 id="前后函数"><a href="#前后函数" class="headerlink" title="前后函数"></a>前后函数</h3><p>​                   <strong>lag(expr,n)                / lead(expr,n)</strong><br>分区中位于当前行前n行（lag）/ 后n行(lead)的记录值<br>示例：查询各部门员工入职间隔天数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span>,datediff(hiredate,前一位员工的入职日期) <span class="keyword">as</span> 间隔天数</span><br><span class="line"><span class="keyword">from</span> (<span class="keyword">select</span> <span class="operator">*</span>,<span class="built_in">lag</span>(hiredate,<span class="number">1</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> deptno <span class="keyword">order</span> <span class="keyword">by</span> hiredate) <span class="keyword">as</span> 前</span><br><span class="line">一位员工的入职日期 <span class="keyword">from</span> emp) <span class="keyword">as</span> t;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------+--------+-----------+------+------------+------+------+--------+----------------------+----------+</span></span><br><span class="line"><span class="operator">|</span> empno <span class="operator">|</span> ename <span class="operator">|</span> job    <span class="operator">|</span> mgr <span class="operator">|</span> hiredate  <span class="operator">|</span> sal <span class="operator">|</span> comm <span class="operator">|</span> deptno <span class="operator">|</span> 前一位员工的入职日期 <span class="operator">|</span> 间隔天数 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+--------+-----------+------+------------+------+------+--------+----------------------+----------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">7782</span> <span class="operator">|</span> clark <span class="operator">|</span> manager  <span class="operator">|</span> <span class="number">7839</span> <span class="operator">|</span> <span class="number">1981</span><span class="number">-06</span><span class="number">-09</span> <span class="operator">|</span> <span class="number">2450</span> <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span>   <span class="number">10</span> <span class="operator">|</span> <span class="keyword">NULL</span>          <span class="operator">|</span>    <span class="keyword">NULL</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">7839</span> <span class="operator">|</span> king  <span class="operator">|</span> persident <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span> <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span> <span class="operator">|</span> <span class="number">5000</span> <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span>   <span class="number">10</span> <span class="operator">|</span> <span class="number">1981</span><span class="number">-06</span><span class="number">-09</span>   <span class="operator">|</span>    <span class="number">161</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">7934</span> <span class="operator">|</span> miller <span class="operator">|</span> clerk   <span class="operator">|</span> <span class="number">7782</span> <span class="operator">|</span> <span class="number">1982</span><span class="number">-01</span><span class="number">-23</span> <span class="operator">|</span> <span class="number">1300</span> <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span>   <span class="number">10</span> <span class="operator">|</span> <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>    <span class="operator">|</span>    <span class="number">67</span>   <span class="operator">|</span></span><br></pre></td></tr></table></figure>


<h3 id="NTILE-函数"><a href="#NTILE-函数" class="headerlink" title="NTILE 函数"></a>NTILE 函数</h3><p>NTILE(n), 用于将分组函数按照顺序切分成n片，返回当前切片值</p>
<p>例如：</p>
<p>统计一个cookie，pv数最多的前1/3的天：取 <code>ntile = 1</code> 的记录，就是我们想要的结果</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cookieid,createtime,pv,</span><br><span class="line"><span class="built_in">NTILE</span>(<span class="number">3</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> pv <span class="keyword">DESC</span>) <span class="keyword">AS</span> ntile </span><br><span class="line"><span class="keyword">FROM</span> test1;</span><br></pre></td></tr></table></figure>
<p><em>注1：如果切片不均匀，<strong>默认增加第一个切片的分布</strong></em><br><em>注2：NTILE不支持ROWS BETWEEN</em></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cookieid,createtime,pv,</span><br><span class="line"><span class="built_in">NTILE</span>(<span class="number">2</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> ntile1,	<span class="comment">--分组内将数据分成2片</span></span><br><span class="line"><span class="built_in">NTILE</span>(<span class="number">3</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> ntile2,  <span class="comment">--分组内将数据分成3片</span></span><br><span class="line"><span class="built_in">NTILE</span>(<span class="number">4</span>) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> cookieid <span class="keyword">ORDER</span> <span class="keyword">BY</span> createtime) <span class="keyword">AS</span> ntile3   <span class="comment">--将所有数据分成4片</span></span><br><span class="line"><span class="keyword">FROM</span> test1 </span><br><span class="line"><span class="comment">-- ...</span></span><br></pre></td></tr></table></figure>


























]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>函数</tag>
      </tags>
  </entry>
  <entry>
    <title>“数智教育”可视化分析</title>
    <url>/2021-01-05-%E2%80%9C%E6%95%B0%E6%99%BA%E6%95%99%E8%82%B2%E2%80%9D%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="“数智教育”可视化分析"><a href="#“数智教育”可视化分析" class="headerlink" title="“数智教育”可视化分析"></a>“数智教育”可视化分析</h1><p><a href="https://public.tableau.com/profile/.58051095#!/vizhome/_luv5ic/1-_?publish=yes">可视化报表地址</a></p>
<p>通过某学校教育数据的数据分析和可视化，探索面向学生、校园的数据分析体系，从而更好服务精细化教学管理工作。</p>
<h2 id="1、目的"><a href="#1、目的" class="headerlink" title="1、目的"></a>1、目的</h2><p>项目来源：<a href="https://tianchi.aliyun.com/competition/entrance/231704/introduction">天池–“数智教育”数据可视化创新大赛</a></p>
<ol>
<li><p>设计分析体系。</p>
</li>
<li><p>使用Navicat, MySQL对数据进行清洗，梳理纬度、新建指标值。</p>
</li>
<li><p>基于分析体系，利用Tableau建立仪表盘组成的动态可视化报表，能够使学校、年级、班级相关人员高效、准确地获取精细信息，从而实施管理或学习。</p>
</li>
</ol>
<p>待更新。。。</p>
]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Tableau</tag>
      </tags>
  </entry>
  <entry>
    <title>XGBoost</title>
    <url>/2021-01-12-XGBoost/</url>
    <content><![CDATA[<h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>XGBoost全称是 etreme gradient boosting，可译为极限梯度提升算法。它由陈天奇所涉及，致力于让提升树突破自身的计算极限，以实现运算快速、性能优秀的工程目标。和传统的梯度提升算法相比，XGBoost进行了许多改进，它能够比其他使用梯度提升的集成算法更加快速，并且已经被认为是在分类和回归上都拥有超高性能的先进评估器。</p>
<h2 id="xgboost库"><a href="#xgboost库" class="headerlink" title="xgboost库"></a>xgboost库</h2><p>xgboost是一个独立的、开源的，专门提供梯度提升树以及XGBoost算法应用的算法库。和sklearn相似，有一个详细的官方网站可供查看，并且可以与 C，Python，R， Julia等语言连用，需要单独下载安装。</p>
<h1 id="二、基本思想"><a href="#二、基本思想" class="headerlink" title="二、基本思想"></a>二、基本思想</h1><p>XGBoost是Boosting算法中的一种。Boosting算法的思想是将许多弱分类器集成在一起形成一个强分类器。因为XGBoost是一种提升树模型，所以它是将许多树模型集成在一起。所用到的树模型是CART回归树模型。</p>
<h2 id="1-CART回归树"><a href="#1-CART回归树" class="headerlink" title="1. CART回归树"></a>1. CART回归树</h2><p>CART回归树是假设树为二叉树，不断将特征进行分裂。实质上就是在该特征维度对样本空间进行划分。</p>
<p>目标：遍历所有特征的所有切分点，找到最优的切分特征和切分点。最终得到一颗回归树。</p>
<h2 id="2-XGBoost算法思想"><a href="#2-XGBoost算法思想" class="headerlink" title="2. XGBoost算法思想"></a>2. XGBoost算法思想</h2><p>算法思想就是不断地不断进行特征分裂来添加树，每次添加一个树，其实是学习一个新函数，去拟合上次预测的残差。当我们训练完成得到k棵树，要预测一个样本的分数就根据这个样本的特征，在每棵树中会落到对应的一个叶子节点，每个叶子节点对应一个分数，最后只需要将每棵树对应的分数加起来就是该样本的预测值。</p>
<p><img src="../images/xgboost/1.png"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210308074101931.png" alt="image-20210308074101931"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210308074114509.png" alt="image-20210308074114509"></p>
<p><img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210308074135159.png" alt="image-20210308074135159"></p>
<h1 id="三、XGBoost基本原理"><a href="#三、XGBoost基本原理" class="headerlink" title="三、XGBoost基本原理"></a>三、XGBoost基本原理</h1><h2 id="1-目标函数"><a href="#1-目标函数" class="headerlink" title="1. 目标函数"></a>1. 目标函数</h2><p><img src="../images/xgboost/2.png"></p>
<ul>
<li>损失函数，可以是平方损失或逻辑损失</li>
<li>正则项，加入正则项的好处是防止过拟合。一是预剪枝，：T代表叶子节点数，γ可以控制叶子节点的个数。二是leaf score的L2模平方系数对leaf score做了平滑：ω代表叶子节点的分数(leaf score)，λ可以控制leaf score不会过大。</li>
</ul>
<p>所以，当生成t棵树后，总体目标就是一方面要最小化Loss 函数，一方面要让树模型更精简。<strong>由此衍生了一个结构分数</strong>，代表了当我们指定一个树的结构时，我们在目标上面最多减多少。类似Gini系数一样的对树结构打分的函数。</p>
<h2 id="2-寻找最佳分支：结构分数之差-Gain"><a href="#2-寻找最佳分支：结构分数之差-Gain" class="headerlink" title="2. 寻找最佳分支：结构分数之差(Gain)"></a>2. 寻找最佳分支：结构分数之差(Gain)</h2><p><img src="../images/xgboost/3.png"></p>
<p>所以在XGB的运行过程中，会根据结构分数寻找最佳的树。</p>
<p><img src="../images/xgboost/4.png"></p>
<h1 id="四、参数简要说明"><a href="#四、参数简要说明" class="headerlink" title="四、参数简要说明"></a>四、参数简要说明</h1><h2 id="1-有放回的随机抽样：参数subsample"><a href="#1-有放回的随机抽样：参数subsample" class="headerlink" title="1. 有放回的随机抽样：参数subsample"></a>1. 有放回的随机抽样：参数subsample</h2><p>在梯度提升树中，每构建一个评估器，都让模型更加集中于数据集中那些容易被判错的样本，加大它们的权重。持续反馈。。。</p>
<h2 id="2-迭代决策树：参数eta"><a href="#2-迭代决策树：参数eta" class="headerlink" title="2. 迭代决策树：参数eta"></a>2. 迭代决策树：参数eta</h2><p>因为模型会更加倾向于攻克那些难以判断的样本，那么，如何构造更好的树？——</p>
<p>除了保证模型逐渐倾向于困难样本的方向，还必须控制新弱分类器的生成，然后让新添加的树是对这个新数据集预测效果最优的那一棵树。</p>
<p>eta是迭代决策树时的步长，又叫做学习率。和逻辑回归里的类型，步长越大，迭代速度越快，很快达到算法极限，有可能无法收敛到真正的最佳，步长越小，越有可能找到更精确的最佳值，但速度会比较慢。</p>
<h2 id="3-选择弱分类器：参数booster"><a href="#3-选择弱分类器：参数booster" class="headerlink" title="3. 选择弱分类器：参数booster"></a>3. 选择弱分类器：参数booster</h2><p>booster可以选择使用什么样的弱评估器，树模型gbtree、线性模型gblinear，</p>
<p>每种评估器对应的params也不同，都有自己的params列表，评估器必须有param参数相匹配。</p>
<h2 id="4-XGB的目标函数：参数objective"><a href="#4-XGB的目标函数：参数objective" class="headerlink" title="4. XGB的目标函数：参数objective"></a>4. XGB的目标函数：参数objective</h2><p>选择不同的损失函数取决于要解决什么问题 ——</p>
<p>回归预测：均方误差RMSE</p>
<p>分类预测：错误率error 或者 对数损失 log_loss</p>
<p>只要选出的函数可微，能够代表某种损失的函数，就可以。</p>
<p>损失函数的核心是衡量模型的泛化能力，即模型在未知数据上的预测的准确与否。XGB是实现了模型表现和运算速度的平衡的算法，因此引入了模型复杂度来衡量算法的运算效率，所以XGB的目标函数被写作：传统损失函数 + 模型复杂度</p>
<p><img src="../images/xgboost/5.png"></p>
<h2 id="5-参数化决策树：参数lambda"><a href="#5-参数化决策树：参数lambda" class="headerlink" title="5. 参数化决策树：参数lambda"></a>5. 参数化决策树：参数lambda</h2><p>调节lambda越大，惩罚越重，正则项比例越大，可以让模型的复杂度变低，对于天生过拟合的XGB来说，可以一定程度上提升模型效果。可以使用网格搜索调整。</p>
<h2 id="6-让树停止生长：参数gamma"><a href="#6-让树停止生长：参数gamma" class="headerlink" title="6. 让树停止生长：参数gamma"></a>6. 让树停止生长：参数gamma</h2><p>gamma可以控制叶子节点的个数，也叫“复杂性控制”，是防止过拟合的重要参数。如何让树停止生长——</p>
<p>在XGB中，我们规定，只要结构分数之差Gain是大于0的，即只要目标函数还能够继续减小，我们就允许树继续进行分支，可以直接通过设定gamma的大小来让XGB中树停止生长，所以gamma也叫：在树的叶子节点上进行进一步分支所需的最小目标函数减少量。gamma越大，算法就越保守，树的叶子数量就越少，模型的复杂度就越低。</p>
<p><img src="../images/xgboost/6.png"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>集成算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>滴滴SQL题</title>
    <url>/2021-01-01-%E6%BB%B4%E6%BB%B4SQL%E9%A2%98/</url>
    <content><![CDATA[<h1 id="滴滴笔试题"><a href="#滴滴笔试题" class="headerlink" title="滴滴笔试题"></a>滴滴笔试题</h1><p>1、 假设某天用户发单量异常，如何分析？</p>
<p>分析这一天的环比、同比数据；这一天是工作日、周末、还是节假日；由于设备还是服务器什么的原因；发生地点？对比其他地点；客群分析</p>
<p>2、 上海虹桥站，6月司机应答后取消率高于去年同期（其他火车站无此现象），如何分析？</p>
<p>环比数据；六月所有数据具体到天、小时；查看机场的异常情况（因为虹桥站跟机场在一起）；跟其他城市对比；查看是谁取消的，司机/用户，by应答时间</p>
<p><a href="https://baijiahao.baidu.com/s?id=1683757374866084787&wfr=spider&for=pc">业务数据分析方法之<strong>异常数据如何分析</strong></a></p>
<p>3、表名：dw_v_order_base</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>order_id</td>
<td>订单编号</td>
</tr>
<tr>
<td>pid</td>
<td>乘客编号</td>
</tr>
<tr>
<td>driver_id</td>
<td>司机编号</td>
</tr>
<tr>
<td>finish_time</td>
<td>完单时间（格式为2019-07-08  17:20:58）</td>
</tr>
<tr>
<td>product_id</td>
<td>完单类型（3,4为快车）</td>
</tr>
<tr>
<td>order_status</td>
<td>订单状态（5为完成订单，7为被取消订单）</td>
</tr>
<tr>
<td>city_name</td>
<td>城市名称</td>
</tr>
<tr>
<td>distance</td>
<td>订单实际距离（单位：km）</td>
</tr>
</tbody></table>
<p>表名：dm.gulf_order_scene</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>order_id</td>
<td>订单编号</td>
</tr>
<tr>
<td>scene_l2</td>
<td>订单场景（‘去火车站’、‘火车站出发’为火车站场景订单）</td>
</tr>
</tbody></table>
<h2 id="分区的乘客数分布"><a href="#分区的乘客数分布" class="headerlink" title="分区的乘客数分布"></a>分区的乘客数分布</h2><p>1）请写出过去一周火车站场景下快车完单量、完单城市关于乘客数分布；</p>
<p>（说明：快车完单数1单 2单 单。。。完单城市北京，上海，深圳。。各情况对应的用户数是多少）</p>
<ul>
<li> <strong>筛选日期</strong>：<code>subdate(curdate(),interval 7 day)</code>；<strong>筛选场景</strong>：<code>scene_l2  like &#39;%火车站%&#39;</code>  ；<strong>筛选类型</strong>是快车；<strong>筛选订单状态</strong>是完单</li>
<li> 按照<strong>乘客和城市分组</strong>，计算每个城市各个乘客的快车完单量 <code>count(distinct order_id)</code></li>
<li> 再按照<strong>完单量和城市分组</strong>，得到相应的用户数<code>count(pid)</code></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> 完单数,city_name,<span class="built_in">count</span>(pid)乘客数 </span><br><span class="line"><span class="keyword">from</span>(<span class="keyword">select</span> pid,city_name, <span class="built_in">count</span>(<span class="keyword">distinct</span> d.order_id)完单数 </span><br><span class="line"><span class="keyword">from</span> dw_v_order_base d <span class="keyword">left</span> <span class="keyword">join</span> gulf_order_scene g <span class="keyword">on</span> d.order_id <span class="operator">=</span> g.order_id</span><br><span class="line"><span class="keyword">where</span> <span class="type">date</span>(finish_time) <span class="operator">&gt;</span> date_sub(curdate(),<span class="type">interval</span> <span class="number">7</span> <span class="keyword">day</span>)</span><br><span class="line"><span class="keyword">and</span> g.scene_l2 <span class="keyword">like</span> <span class="string">&#x27;%火车站%&#x27;</span> <span class="keyword">and</span> d.product_id <span class="keyword">in</span> (<span class="number">3</span>,<span class="number">4</span>) <span class="keyword">and</span> d.order_status <span class="operator">=</span><span class="number">5</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> pid,city_name)t</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> 完单数,city_name;</span><br></pre></td></tr></table></figure>
<p><img src="../images/1.png"></p>
<h2 id="分里程时段的订单量分布"><a href="#分里程时段的订单量分布" class="headerlink" title="分里程时段的订单量分布"></a>分里程时段的订单量分布</h2><p>2）请写出过去一个月各城市分里程分时段快车完单量的分布；（无从得知怎么对时段里程分区的情况下，按照滴滴的产品计费规则理解）</p>
<ul>
<li><strong>筛选日期</strong>：<code>subdate(curdate(),interval 1 month)</code>；<strong>筛选类型</strong>是快车；<strong>筛选订单状态</strong>是完单</li>
<li>时段分组 6-21是普通时段，其余是特殊时段；里程分组：0-8,8-15,15-40,40以上；在select里查询为单独列</li>
<li>然后按照<strong>城市，里程区间，时段区间分组</strong></li>
<li>计算每个分组里的订单量</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> city_name,</span><br><span class="line">	   if(distance<span class="operator">&lt;=</span><span class="number">8</span>,<span class="string">&#x27;0-8公里&#x27;</span>,if(distance<span class="operator">&lt;=</span><span class="number">15</span>,<span class="string">&#x27;8-15公里&#x27;</span>,if(distance<span class="operator">&lt;=</span><span class="number">40</span>,<span class="string">&#x27;15-40公里&#x27;</span>,<span class="string">&#x27;40公里以上&#x27;</span>))) 里程,</span><br><span class="line">       if(<span class="keyword">hour</span>(finish_time)<span class="operator">&gt;=</span><span class="number">6</span> <span class="keyword">and</span> <span class="keyword">hour</span>(finish_time)<span class="operator">&lt;</span><span class="number">21</span>,<span class="string">&#x27;普通时段&#x27;</span>,<span class="string">&#x27;特殊时段&#x27;</span>) 时段,</span><br><span class="line">       <span class="built_in">count</span>(<span class="keyword">distinct</span> order_id)快车完单量</span><br><span class="line"><span class="keyword">from</span> dw_v_order_base d </span><br><span class="line"><span class="keyword">where</span> <span class="type">date</span>(finish_time) <span class="operator">&gt;</span> date_sub(curdate(),<span class="type">interval</span> <span class="number">1</span> <span class="keyword">month</span>)</span><br><span class="line"><span class="keyword">and</span> d.product_id <span class="keyword">in</span> (<span class="number">3</span>,<span class="number">4</span>) <span class="keyword">and</span> d.order_status <span class="operator">=</span><span class="number">5</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> city_name,if(distance<span class="operator">&lt;=</span><span class="number">8</span>,<span class="string">&#x27;0-8公里&#x27;</span>,if(distance<span class="operator">&lt;=</span><span class="number">15</span>,<span class="string">&#x27;8-15公里&#x27;</span>,if(distance<span class="operator">&lt;=</span><span class="number">40</span>,<span class="string">&#x27;15-40公里&#x27;</span>,<span class="string">&#x27;40公里以上&#x27;</span>))),if(<span class="keyword">hour</span>(finish_time)<span class="operator">&gt;=</span><span class="number">6</span> <span class="keyword">and</span> <span class="keyword">hour</span>(finish_time)<span class="operator">&lt;</span><span class="number">21</span>,<span class="string">&#x27;普通时段&#x27;</span>,<span class="string">&#x27;特殊时段&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><img src="../images/2.png"> </p>
<h2 id="日留存率"><a href="#日留存率" class="headerlink" title="日留存率"></a>日留存率</h2><p>3）2020-05-01快车完单用户在之后一周内日留存率；</p>
<ul>
<li><strong>筛选日期</strong>：<code>date(finish_time) between&#39;2020-05-01&#39; and &#39;2020-05-08&#39;</code>；<strong>筛选类型</strong>是快车；<strong>筛选订单状态</strong>是完单；得到符合以上条件的<strong>用户u</strong></li>
<li><strong>在用户u的基础上</strong>，<strong>筛选日期</strong><code>date(finish_time) between&#39;2020-05-02&#39; and &#39;2020-05-08&#39;</code> ，<strong>按照完单日期分组</strong>，用<strong>每个完单日期与05-01的差</strong>得到留存天数，对每个分组内的用户数计数得到<strong>日留存用户数</strong></li>
<li><strong>日留存率 = 日留存用户数/05-01的总用户数</strong> </li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 2020-05-01快车完单总用户数</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> pid <span class="keyword">from</span> dw_v_order_base d </span><br><span class="line"><span class="keyword">where</span> <span class="type">date</span>(d.finish_time)<span class="operator">=</span><span class="string">&#x27;2020-05-01&#x27;</span> <span class="keyword">and</span> d.product_id <span class="keyword">in</span> (<span class="number">3</span>,<span class="number">4</span>) <span class="keyword">and</span> d.order_status <span class="operator">=</span><span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 2020-05-02至2020-05-08的日留存率</span></span><br><span class="line"><span class="keyword">select</span> timestampdiff(<span class="keyword">day</span>,<span class="string">&#x27;2020-05-01&#x27;</span>,<span class="type">date</span>(d.finish_time)) 留存天数,</span><br><span class="line">	  <span class="built_in">count</span>(<span class="keyword">distinct</span> d.pid) 留存用户数,</span><br><span class="line">      <span class="built_in">count</span>(<span class="keyword">distinct</span> d.pid)<span class="operator">/</span>(<span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> pid) <span class="keyword">from</span> dw_v_order_base d </span><br><span class="line"><span class="keyword">where</span> <span class="type">date</span>(d.finish_time)<span class="operator">=</span><span class="string">&#x27;2020-05-01&#x27;</span> <span class="keyword">and</span> d.product_id <span class="keyword">in</span> (<span class="number">3</span>,<span class="number">4</span>) <span class="keyword">and</span> d.order_status <span class="operator">=</span><span class="number">5</span>)留存率</span><br><span class="line"><span class="keyword">from</span> dw_v_order_base d </span><br><span class="line"><span class="keyword">where</span> <span class="type">date</span>(d.finish_time) <span class="keyword">between</span> <span class="string">&#x27;2020-05-02&#x27;</span> <span class="keyword">and</span> <span class="string">&#x27;2020-05-08&#x27;</span></span><br><span class="line"><span class="keyword">and</span> d.pid <span class="keyword">in</span> (<span class="keyword">select</span> <span class="keyword">distinct</span> pid <span class="keyword">from</span> dw_v_order_base d </span><br><span class="line"><span class="keyword">where</span> <span class="type">date</span>(d.finish_time)<span class="operator">=</span><span class="string">&#x27;2020-05-01&#x27;</span> <span class="keyword">and</span> d.product_id <span class="keyword">in</span> (<span class="number">3</span>,<span class="number">4</span>) <span class="keyword">and</span> d.order_status <span class="operator">=</span><span class="number">5</span>)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="type">date</span>(d.finish_time);</span><br></pre></td></tr></table></figure>
<p><img src="../images/3.png"></p>
<h2 id="连续完单天数最长"><a href="#连续完单天数最长" class="headerlink" title="连续完单天数最长"></a>连续完单天数最长</h2><p>4）选出各城市连续完单天数最长的快车司机（加分题）；</p>
<ul>
<li><strong>筛选类型</strong>是快车；<strong>筛选订单状态</strong>是完单，查找不重复城市、司机、完单日期（也可以按照城市、司机、完单日期分组）得到t1</li>
<li>在t1上，对每个城市，每个司机的订单日期使用开窗函数，按照城市、司机进行排序，再用每个完单日期减去排序值，得到的分组日期可以<strong>对连续日期分组</strong>，得到t2</li>
<li>在t2上，对城市、司机、分组日期进行分组，对每一行都进行最大连续日期的计算（用开窗函数按照城市分组），再与每个司机的连续完单日期进行对比，匹配到该城市完成最大连续日期的司机是谁。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">	city_name,</span><br><span class="line">    driver_id,</span><br><span class="line">    司机连续完单天数</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">(<span class="keyword">select</span> </span><br><span class="line">	city_name,</span><br><span class="line">    driver_id,</span><br><span class="line">    分组日期,</span><br><span class="line">    <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> 司机连续完单天数,</span><br><span class="line">    <span class="built_in">max</span>(<span class="built_in">count</span>(<span class="operator">*</span>)) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> city_name) <span class="keyword">as</span> 城市最长连续完单天数</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">(<span class="keyword">select</span> </span><br><span class="line">	<span class="operator">*</span>,</span><br><span class="line">    <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> city_name,driver_id <span class="keyword">order</span> <span class="keyword">by</span> 完单日期) <span class="keyword">as</span> 序号,</span><br><span class="line">    subdate(完单日期,<span class="type">interval</span> <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> city_name,driver_id <span class="keyword">order</span> <span class="keyword">by</span> 完单日期) <span class="keyword">day</span>) <span class="keyword">as</span> 分组日期</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">(<span class="keyword">select</span> <span class="keyword">distinct</span> city_name,driver_id,<span class="type">date</span>(finish_time) <span class="keyword">as</span> 完单日期</span><br><span class="line"><span class="keyword">from</span> dw_v_order_base) <span class="keyword">as</span> t1) <span class="keyword">as</span> t2</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> city_name,driver_id,分组日期) <span class="keyword">as</span> t3</span><br><span class="line"><span class="keyword">where</span> 司机连续完单天数<span class="operator">=</span>城市最长连续完单天数;</span><br></pre></td></tr></table></figure>
<p><img src="../images/4.png"></p>
]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>题解</tag>
      </tags>
  </entry>
  <entry>
    <title>随机森林</title>
    <url>/2021-01-15-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</url>
    <content><![CDATA[<p> bagging方法的代表算法是随机森林，准确的来说，随机森林是bagging的⼀个特化进阶版，所谓的特化是因为随机森林的弱学习器都是决策树。所谓的进阶是随机森林在bagging的样本随机采样基础上，⼜加上了特征的随机选择，其基本思想没有脱离bagging的范畴。分类树组成的森林就叫做随机森林分类器，回归树所集成的森林就叫做随机森林回归器。</p>
<p>什么是集成算法和bagging？——</p>
<p><strong>集成算法</strong></p>
<p>对于训练集数据，我们通过训练若⼲个弱评估器，通过⼀定的结合策略，就可以最终形成⼀个强评估器，这个强分类器的效果就是汇总之前多个模型的结果，来获取最优的表现结果。</p>
<p>它可以⽤来做市场营销模拟的建模，统计客户来源，保留和流失，也可⽤来预测疾病的⻛险和病患者的易感性。</p>
<p><strong>Bagging</strong></p>
<p><strong>原理</strong>：每次均匀地、有放回地随机选取与原数据集样本量相等的样本，得到若干个新数据集。再用若干个若评估器分别训练这些数据集，最终对每个评估器预测的结果根据平均或多数表决原则选取最优的预测结果。</p>
<p><img src="../images/rf/2.png"></p>
<h1 id="一、随机森林分类器"><a href="#一、随机森林分类器" class="headerlink" title="一、随机森林分类器"></a>一、随机森林分类器</h1><p>通过构造多个决策树，做bagging以提高泛化能力 </p>
<p>有哪些随机方法</p>
<h2 id="1-重要参数"><a href="#1-重要参数" class="headerlink" title="1. 重要参数"></a>1. 重要参数</h2><h3 id="1-1-控制基评估器的参数"><a href="#1-1-控制基评估器的参数" class="headerlink" title="1.1 控制基评估器的参数"></a>1.1 控制基评估器的参数</h3><table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>criterion</td>
<td><strong>不纯度的衡量指标</strong>，有基尼系数和信息熵两种选择</td>
</tr>
<tr>
<td>max_depth</td>
<td>树的最大深度，超过最⼤深度的树枝都会被剪掉</td>
</tr>
<tr>
<td>min_samples_leaf</td>
<td>⼀个节点<strong>在分枝后的每个⼦节点</strong>都必须包含⾄少min_samples_leaf个训练样本，否则分枝就不会发⽣</td>
</tr>
<tr>
<td>min_samples_split</td>
<td><strong>⼀个节点必须要包含</strong>⾄少min_samples_split个训练样本，这个节点才允许被分枝，否则分枝就不会发⽣</td>
</tr>
<tr>
<td>max_features</td>
<td>max_features限制分枝时考虑的特征个数，超过限制个数的特征都会被舍弃，<strong>默认值为总特征个数开平⽅取整</strong></td>
</tr>
<tr>
<td>min_impurity_decrease</td>
<td>限制信息增益的⼤⼩，信息增益⼩于设定数值的分枝不会发⽣</td>
</tr>
</tbody></table>
<h3 id="1-2-n-estimators"><a href="#1-2-n-estimators" class="headerlink" title="1.2 n_estimators"></a>1.2 n_estimators</h3><p>森林中树⽊的数量，即基评估器的数量。这个参数对随机森林模型的精确性影响是单调的，n_estimators越⼤，模型的效果往往越好。但是达到⼀定的程度之后，随机森林的精确性往往不再上升或开始波动，并且，n_estimators越⼤，需要的计算量和内存也越⼤，训练的时间也会越来越⻓。对于这个参数，目标是尽量在训练难度和模型效果之间取得平衡。</p>
<h3 id="1-3-random-state"><a href="#1-3-random-state" class="headerlink" title="1.3 random_state"></a>1.3 random_state</h3><p>sklearn中的分类树DecisionTreeClassifier自带随机性，所以随机森林中的树天⽣就都是不⼀样的。分类树中的参数数random_state是 从最重要的特征中随机选择出⼀个特征来进⾏分枝，因此每次⽣成的决策树都不⼀样。随机森林⽤法和分类树中相似，只不过在分类树中，⼀个random_state只<br>控制⽣成⼀棵树，⽽随机森林中的random_state控制的是⽣成森林的模式，⽽⾮让⼀个森林中有⼀<br>棵树。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#随机森林中的random_state控制的是⽣成森林的模式</span></span><br><span class="line">rfc = RandomForestClassifier(n_estimators=<span class="number">20</span>,random_state=<span class="number">2</span>)</span><br><span class="line">rfc = rfc.fit(Xtrain, Ytrain)</span><br><span class="line"><span class="comment">#随机森林的重要属性之⼀：estimators，查看森林中树的状况</span></span><br><span class="line">rfc.estimators_[<span class="number">0</span>].random_state</span><br><span class="line"><span class="comment">#打印出森林中所有树的随机模式</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(rfc.estimators_)):</span><br><span class="line">    print(rfc.estimators_[i].random_state)</span><br></pre></td></tr></table></figure>
<p>当我们需要成千上万棵树的时候，数据不⼀定能够提供成千上万的特征来让我们构筑尽量多尽量不同的树。因此，除了random_state。我们还需要其他的随机性，比如max_features。</p>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>给每一个训练样本赋予一个等量的初始权重，在每一轮训练结束时自动地调整权重。</p>
<p><img src="../images/rf/1.png"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>集成算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>酒店预订平台用户流失概率预测</title>
    <url>/2021-01-11-Prediction_of_User_Churn/</url>
    <content><![CDATA[<h1 id="酒店预订平台用户流失概率预测"><a href="#酒店预订平台用户流失概率预测" class="headerlink" title="酒店预订平台用户流失概率预测"></a>酒店预订平台用户流失概率预测</h1><h2 id="1、项目介绍"><a href="#1、项目介绍" class="headerlink" title="1、项目介绍"></a>1、项目介绍</h2><p>某酒店预订平台所属公司作为中国领先的综合性旅行服务公司，每天向超过2.5亿会员提供全方位的旅行服务，在这海量的网站访问量中，我们可分析用户的行为数据来挖掘潜在的信息资源。其中，客户流失率是考量业务成绩的一个非常关键的指标。此次分析的目的是为了<strong>深入了解用户画像及行为偏好，找到最优算法，挖掘出影响用户流失的关键因素</strong>，从而更好地完善产品设计、提升用户体验！</p>
<ul>
<li><p>目的<br>分析影响客户流失的关键因素，并通过算法预测客户访问的转化结果。</p>
</li>
<li><p>评估标准<br>评分指标为97%精确度下的召回率，即：在precision&gt;=0.97的recall中，选取max(recall)。</p>
</li>
<li><p>数据集<br>数据集包括49个指标（2016年5月16至21日期间一周的数据），689945行，预测的目标样本为流失样本(即label=1)，将这些指标按订单相关、酒店相关和客户行为相关进行归类。</p>
<img src="../images/19.PNG"  />



</li>
</ul>
<h2 id="2、项目流程"><a href="#2、项目流程" class="headerlink" title="2、项目流程"></a>2、项目流程</h2><h3 id="2-1-数据预处理"><a href="#2-1-数据预处理" class="headerlink" title="2.1 数据预处理"></a>2.1 数据预处理</h3><h4 id="2-1-1-目标特征分布"><a href="#2-1-1-目标特征分布" class="headerlink" title="2.1.1 目标特征分布"></a>2.1.1 目标特征分布</h4><p>导入相应包和数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler,OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">df_orign = pd.read_csv(<span class="string">&#x27;userlostprob_train.txt&#x27;</span>, sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">df = df_orign.copy()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In[<span class="number">1</span>]: df[<span class="string">&#x27;label&#x27;</span>].value_counts()</span><br><span class="line">Out[<span class="number">1</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">500588</span></span><br><span class="line"><span class="number">1</span>    <span class="number">189357</span></span><br><span class="line">Name: label, dtype: int64</span><br></pre></td></tr></table></figure>
<p>流失和未流失的用户比例<strong>2:5</strong>，样本不是非常不平衡，所以不做处理。</p>
<p>但也可以处理，这里想到两个方法：</p>
<p>1、对小类样本错分进行加权惩罚</p>
<p>2、数据重采样（大样本欠采样，小样本过采样）</p>
<h4 id="2-1-2-处理异常值"><a href="#2-1-2-处理异常值" class="headerlink" title="2.1.2 处理异常值"></a>2.1.2 处理异常值</h4><p><strong>1、负值</strong></p>
<ul>
<li>用户偏好价格delta_price1(132816条)、delta_price2(134606条)，以及当前酒店可订最低价lowestprice(1条)，理论上酒店的价格不可能为负，考虑到可能是因为优惠折扣的原因，因此<strong>采取0填充</strong>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[[<span class="string">&#x27;delta_price1&#x27;</span>,<span class="string">&#x27;delta_price2&#x27;</span>,<span class="string">&#x27;lowestprice&#x27;</span>]] = df[[<span class="string">&#x27;delta_price1&#x27;</span>,<span class="string">&#x27;delta_price2&#x27;</span>,<span class="string">&#x27;lowestprice&#x27;</span>]].applymap(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x&lt;<span class="number">0</span> <span class="keyword">else</span> x)</span><br></pre></td></tr></table></figure>
<ul>
<li>客户价值customer_value_profit、ctrip_profits为负值，一开始我觉得肯定出错，后来思考加搜索得出：用户价值可以为负，如果一个用户的行为，导致其他用户的极大反感，并造成了其他用户的流失和粘性下降，就是用户的负面价值。典型如喷子，杠精，游戏中的外挂用户等。<strong>所以这里不作处理</strong></li>
</ul>
<ul>
<li>deltaprice_pre2_t1是酒店价格与对手价差均值，可以为负值，<strong>无需处理</strong>。</li>
</ul>
<p><strong>2、异常值</strong></p>
<p>24小时内登陆时长内登录时长不应该超过24小时，将大于24的值改为24</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ano_values1=[<span class="string">&#x27;delta_price1&#x27;</span>,<span class="string">&#x27;delta_price2&#x27;</span>,<span class="string">&#x27;lowestprice&#x27;</span>]</span><br><span class="line">ano_values2=[<span class="string">&#x27;customer_value_profit&#x27;</span>,<span class="string">&#x27;ctrip_profits&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> ano_values1:</span><br><span class="line">    df.loc[df[col]&lt;<span class="number">0</span>,col]=df[col].median()  <span class="comment"># 填充中位数</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> ano_values2:</span><br><span class="line">    df.loc[df[col]&lt;<span class="number">0</span>,col]=<span class="number">0</span>  <span class="comment"># 填充0</span></span><br><span class="line"></span><br><span class="line">df.loc[df[<span class="string">&#x27;landhalfhours&#x27;</span>]&gt;<span class="number">24</span>,[<span class="string">&#x27;landhalfhours&#x27;</span>]] = <span class="number">24</span></span><br></pre></td></tr></table></figure>


<h4 id="2-1-3-处理缺失值"><a href="#2-1-3-处理缺失值" class="headerlink" title="2.1.3 处理缺失值"></a>2.1.3 处理缺失值</h4><p><strong>各个字段缺失值情况：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">na_rate = (<span class="built_in">len</span>(df)-df.count())/<span class="built_in">len</span>(df)</span><br><span class="line">na_rate_order = na_rate.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">na_rate_order.head()</span><br><span class="line">Out[<span class="number">5</span>]: </span><br><span class="line">historyvisit_7ordernum              <span class="number">0.879824</span></span><br><span class="line">historyvisit_visit_detailpagenum    <span class="number">0.554698</span></span><br><span class="line">firstorder_bu                       <span class="number">0.453590</span></span><br><span class="line">decisionhabit_user                  <span class="number">0.441332</span></span><br><span class="line">historyvisit_totalordernum          <span class="number">0.439774</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>缺失值太多了，画图也看不清，知道第一位缺失87%可以直接删除了</p>
<p><strong>计算相关性</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_corr = df[df.columns.values.tolist()].corr()</span><br><span class="line">df_na = na_rate_order[na_rate_order&gt;<span class="number">0</span>].index.tolist()</span><br><span class="line"><span class="built_in">len</span>(df_na) <span class="comment">#有多少缺失值呢</span></span><br><span class="line">df_na_corr = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df_na:</span><br><span class="line">    df_na_corr[i] = df_corr[i].sort_values(ascending=<span class="literal">False</span>)[[<span class="number">1</span>]]</span><br><span class="line">df_na_corr  <span class="comment">#查看这些缺失值互相的相关性</span></span><br></pre></td></tr></table></figure>
<p>1、字段’historyvisit_7ordernum ‘缺失程度太高，遂删去。</p>
<p>2、其他字段：这里通过查看它们的相关性、缺失程度、数据类型考虑以下几种填充办法</p>
<h5 id="2-1-3-1-用其他字段组合填充"><a href="#2-1-3-1-用其他字段组合填充" class="headerlink" title="2.1.3.1 用其他字段组合填充"></a>2.1.3.1 用其他字段组合填充</h5><p>这里的标准是，相关性高，字段取值一定程度上可以代替彼此，比如</p>
<p>commentnums_pre(24小时历史浏览次数最多酒店<strong>点评数</strong>)和novoters_pre(24小时历史浏览次数最多酒店<strong>评分人数</strong>)；commentnums_pre2(24小时历史浏览次数最多酒店<strong>点评数均值</strong>)和novoters_pre2(24小时历史浏览酒店<strong>评分人数均值</strong>)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;commentnums&#x27;</span>: novoters    <span class="number">0.992748</span></span><br><span class="line"><span class="string">&#x27;commentnums_pre2&#x27;</span>: novoters_pre2    <span class="number">0.985438</span></span><br><span class="line"><span class="comment"># 相关性都很高</span></span><br></pre></td></tr></table></figure>
<p>如何组合？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(df[<span class="string">&#x27;commentnums_pre&#x27;</span>]/df[<span class="string">&#x27;novoters_pre&#x27;</span>]).describe()</span><br><span class="line">Out[<span class="number">13</span>]: </span><br><span class="line">count    <span class="number">597927.000000</span></span><br><span class="line">mean          <span class="number">0.664643</span></span><br><span class="line">std           <span class="number">1.187749</span></span><br><span class="line"><span class="built_in">min</span>           <span class="number">0.000000</span></span><br><span class="line"><span class="number">25</span>%           <span class="number">0.538941</span></span><br><span class="line"><span class="number">50</span>%           <span class="number">0.656166</span></span><br><span class="line"><span class="number">75</span>%           <span class="number">0.733766</span></span><br><span class="line"><span class="built_in">max</span>         <span class="number">160.000000</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>可以看到 二者的比值的中位数是 0.656166。可以理解为2/5=2.5 那么2*2.5可以==5, </p>
<p>5/2.5==2</p>
<p>所以就用novoters_prenovoters_pre*65% 填充 commentnums_pre；</p>
<p> commentnums_pre/65% 填充 novoters_prenovoters_pre</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 填充commentnums_pre和novoters_pre的部分缺失值，剩余缺失值用中位数填充。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill_commentnum_novoter_pre</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> (x.isnull()[<span class="string">&#x27;commentnums_pre&#x27;</span>])&amp;(x.notnull()[<span class="string">&#x27;novoters_pre&#x27;</span>]):</span><br><span class="line">        x[<span class="string">&#x27;commentnums_pre&#x27;</span>] = x[<span class="string">&#x27;novoters_pre&#x27;</span>]*<span class="number">0.65</span></span><br><span class="line">    <span class="keyword">elif</span> (x.notnull()[<span class="string">&#x27;commentnums_pre&#x27;</span>])&amp;(x.isnull()[<span class="string">&#x27;novoters_pre&#x27;</span>]):</span><br><span class="line">        x[<span class="string">&#x27;novoters_pre&#x27;</span>] = x[<span class="string">&#x27;commentnums_pre&#x27;</span>]/<span class="number">0.65</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">df[[<span class="string">&#x27;commentnums_pre&#x27;</span>,<span class="string">&#x27;novoters_pre&#x27;</span>]] = df[[<span class="string">&#x27;commentnums_pre&#x27;</span>,<span class="string">&#x27;novoters_pre&#x27;</span>]].apply(fill_commentnum_novoter_pre,axis=<span class="number">1</span>)</span><br><span class="line">df[[<span class="string">&#x27;commentnums_pre&#x27;</span>,<span class="string">&#x27;novoters_pre&#x27;</span>]].info()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 填充commentnums_pre2和novoters_pre2字段，剩余缺失值用均值填充。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fill_commentnum_novoter_pre2</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> (x.isnull()[<span class="string">&#x27;commentnums_pre2&#x27;</span>])&amp;(x.notnull()[<span class="string">&#x27;novoters_pre2&#x27;</span>]):</span><br><span class="line">        x[<span class="string">&#x27;commentnums_pre2&#x27;</span>] = x[<span class="string">&#x27;novoters_pre2&#x27;</span>]*<span class="number">0.65</span></span><br><span class="line">    <span class="keyword">elif</span> (x.notnull()[<span class="string">&#x27;commentnums_pre2&#x27;</span>])&amp;(x.isnull()[<span class="string">&#x27;novoters_pre2&#x27;</span>]):</span><br><span class="line">        x[<span class="string">&#x27;novoters_pre2&#x27;</span>] = x[<span class="string">&#x27;commentnums_pre2&#x27;</span>]/<span class="number">0.65</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">df[[<span class="string">&#x27;commentnums_pre2&#x27;</span>,<span class="string">&#x27;novoters_pre2&#x27;</span>]] = df[[<span class="string">&#x27;commentnums_pre2&#x27;</span>,<span class="string">&#x27;novoters_pre2&#x27;</span>]].apply(fill_commentnum_novoter_pre2,axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h5 id="2-1-3-2-均值、中位数、0填充"><a href="#2-1-3-2-均值、中位数、0填充" class="headerlink" title="2.1.3.2 均值、中位数、0填充"></a>2.1.3.2 均值、中位数、0填充</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#均值（极端值影响不大，符合近似正态分布的字段）</span></span><br><span class="line">fill_mean = [<span class="string">&#x27;cancelrate&#x27;</span>,<span class="string">&#x27;landhalfhours&#x27;</span>,<span class="string">&#x27;visitnum_oneyear&#x27;</span>,<span class="string">&#x27;starprefer&#x27;</span>,<span class="string">&#x27;price_sensitive&#x27;</span>,<span class="string">&#x27;lowestprice&#x27;</span>,<span class="string">&#x27;customereval_pre2&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;uv_pre2&#x27;</span>,<span class="string">&#x27;lowestprice_pre2&#x27;</span>,<span class="string">&#x27;novoters_pre2&#x27;</span>,<span class="string">&#x27;commentnums_pre2&#x27;</span>,<span class="string">&#x27;businessrate_pre2&#x27;</span>,<span class="string">&#x27;lowestprice_pre&#x27;</span>,<span class="string">&#x27;hotelcr&#x27;</span>,<span class="string">&#x27;cancelrate_pre&#x27;</span>]</span><br><span class="line">df[fill_mean] = df[fill_mean].apply(<span class="keyword">lambda</span> x:x.fillna(x.mean()))</span><br><span class="line"><span class="comment">#中位数 (右偏分布的字段)</span></span><br><span class="line">fill_median = [<span class="string">&#x27;ordernum_oneyear&#x27;</span>,<span class="string">&#x27;commentnums_pre&#x27;</span>,<span class="string">&#x27;novoters_pre&#x27;</span>,<span class="string">&#x27;uv_pre&#x27;</span>,<span class="string">&#x27;ordercanncelednum&#x27;</span>,<span class="string">&#x27;ordercanceledprecent&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;lasthtlordergap&#x27;</span>,<span class="string">&#x27;cityuvs&#x27;</span>,<span class="string">&#x27;cityorders&#x27;</span>,<span class="string">&#x27;lastpvgap&#x27;</span>,<span class="string">&#x27;historyvisit_avghotelnum&#x27;</span>,<span class="string">&#x27;businessrate_pre&#x27;</span>,<span class="string">&#x27;cr&#x27;</span>,<span class="string">&#x27;uv_pre&#x27;</span>,<span class="string">&#x27;cr_pre&#x27;</span></span><br><span class="line">                ,<span class="string">&#x27;novoters_pre&#x27;</span>,<span class="string">&#x27;commentnums_pre&#x27;</span>,<span class="string">&#x27;novoters&#x27;</span>,<span class="string">&#x27;hoteluv&#x27;</span>,<span class="string">&#x27;ctrip_profits&#x27;</span>,<span class="string">&#x27;customer_value_profit&#x27;</span>]</span><br><span class="line">df[fill_median] = df[fill_median].apply(<span class="keyword">lambda</span> x:x.fillna(x.median()))</span><br><span class="line"><span class="comment">#0填充</span></span><br><span class="line">df[[<span class="string">&#x27;deltaprice_pre2_t1&#x27;</span>,<span class="string">&#x27;historyvisit_visit_detailpagenum&#x27;</span>]] = df[[<span class="string">&#x27;deltaprice_pre2_t1&#x27;</span>,<span class="string">&#x27;historyvisit_visit_detailpagenum&#x27;</span>]].apply(<span class="keyword">lambda</span> x:x.fillna(<span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<h5 id="2-1-3-3-用其他字段聚类自身分段填充"><a href="#2-1-3-3-用其他字段聚类自身分段填充" class="headerlink" title="2.1.3.3 用其他字段聚类自身分段填充"></a>2.1.3.3 用其他字段聚类自身分段填充</h5><p>填充consuming_capacity，其实这一步是为了得到完整的consuming_capacity然后填充与其相关性较强的avgprice</p>
<p>查看与consuming_capacity相关性高的特征：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df_corr[&#39;consuming_capacity&#39;].sort_values(ascending&#x3D;False)[[0,1,2,3]]</span><br><span class="line">Out[14]: </span><br><span class="line">consuming_capacity    1.000000</span><br><span class="line">avgprice              0.880680</span><br><span class="line">starprefer            0.715734</span><br><span class="line">customereval_pre2     0.420362</span><br><span class="line">Name: consuming_capacity, dtype: float64</span><br></pre></td></tr></table></figure>
<p>所以可以用starprefer来尝试填充，先查看二者数据分布</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[[<span class="string">&#x27;consuming_capacity&#x27;</span>,<span class="string">&#x27;starprefer&#x27;</span>]].describe()</span><br><span class="line">Out[<span class="number">15</span>]: </span><br><span class="line">       consuming_capacity     starprefer</span><br><span class="line">count       <span class="number">463837.000000</span>  <span class="number">464892.000000</span></span><br><span class="line">mean            <span class="number">39.154140</span>      <span class="number">67.532304</span></span><br><span class="line">std             <span class="number">23.240147</span>      <span class="number">19.175094</span></span><br><span class="line"><span class="built_in">min</span>              <span class="number">0.000000</span>       <span class="number">0.000000</span></span><br><span class="line"><span class="number">25</span>%             <span class="number">22.000000</span>      <span class="number">53.300000</span></span><br><span class="line"><span class="number">50</span>%             <span class="number">33.000000</span>      <span class="number">69.400000</span></span><br><span class="line"><span class="number">75</span>%             <span class="number">51.000000</span>      <span class="number">80.300000</span></span><br><span class="line"><span class="built_in">max</span>            <span class="number">100.000000</span>     <span class="number">100.000000</span></span><br><span class="line"></span><br><span class="line">df.loc[df[<span class="string">&#x27;starprefer&#x27;</span>]&lt;<span class="number">60</span>,[<span class="string">&#x27;onsuming_capacity&#x27;</span>,<span class="string">&#x27;starprefer&#x27;</span>]].describe()</span><br><span class="line">Out[<span class="number">16</span>]: </span><br><span class="line">       onsuming_capacity     starprefer</span><br><span class="line">count                <span class="number">0.0</span>  <span class="number">382538.000000</span></span><br><span class="line">mean                 NaN      <span class="number">63.239940</span></span><br><span class="line">std                  NaN      <span class="number">17.682719</span></span><br><span class="line"><span class="built_in">min</span>                  NaN       <span class="number">0.000000</span></span><br><span class="line"><span class="number">25</span>%                  NaN      <span class="number">50.000000</span></span><br><span class="line"><span class="number">50</span>%                  NaN      <span class="number">63.300000</span></span><br><span class="line"><span class="number">75</span>%                  NaN      <span class="number">78.000000</span></span><br><span class="line"><span class="built_in">max</span>                  NaN     <span class="number">100.000000</span></span><br><span class="line"></span><br><span class="line">df.loc[(df[<span class="string">&#x27;starprefer&#x27;</span>]&lt;<span class="number">80</span>)&amp;(df[<span class="string">&#x27;starprefer&#x27;</span>]&gt;=<span class="number">60</span>),[<span class="string">&#x27;onsuming_capacity&#x27;</span>,<span class="string">&#x27;starprefer&#x27;</span>]].describe()</span><br><span class="line">Out[<span class="number">17</span>]: </span><br><span class="line">       onsuming_capacity    starprefer</span><br><span class="line">count                <span class="number">0.0</span>  <span class="number">43238.000000</span></span><br><span class="line">mean                 NaN     <span class="number">85.389345</span></span><br><span class="line">std                  NaN     <span class="number">11.080582</span></span><br><span class="line"><span class="built_in">min</span>                  NaN      <span class="number">0.000000</span></span><br><span class="line"><span class="number">25</span>%                  NaN     <span class="number">80.000000</span></span><br><span class="line"><span class="number">50</span>%                  NaN     <span class="number">86.700000</span></span><br><span class="line"><span class="number">75</span>%                  NaN     <span class="number">92.900000</span></span><br><span class="line"><span class="built_in">max</span>                  NaN    <span class="number">100.000000</span></span><br><span class="line"></span><br><span class="line">df.loc[df[<span class="string">&#x27;starprefer&#x27;</span>]&gt;=<span class="number">80</span>,[<span class="string">&#x27;onsuming_capacity&#x27;</span>,<span class="string">&#x27;starprefer&#x27;</span>]].describe()</span><br></pre></td></tr></table></figure>
<p>综上，用starprefe把consuming_capacity分成三个区间，每个区间内的空值用均值来填充。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 分段填充consuming_capacity</span><br><span class="line">fill1 &#x3D; df.loc[df[&#39;starprefer&#39;]&lt;60,[&#39;consuming_capacity&#39;]].mean()</span><br><span class="line">fill2 &#x3D; df.loc[(df[&#39;starprefer&#39;]&lt;80)&amp;(df[&#39;starprefer&#39;]&gt;&#x3D;60),[&#39;consuming_capacity&#39;]].mean()</span><br><span class="line">fill3 &#x3D; df.loc[df[&#39;starprefer&#39;]&gt;&#x3D;80,[&#39;consuming_capacity&#39;]].mean()</span><br><span class="line">def fill_consuming_capacity(x):</span><br><span class="line">    if x.isnull()[&#39;consuming_capacity&#39;]:</span><br><span class="line">        if x[&#39;starprefer&#39;]&lt;60:</span><br><span class="line">            x[&#39;consuming_capacity&#39;] &#x3D; fill1</span><br><span class="line">        elif (x[&#39;starprefer&#39;]&lt;80)&amp;(x[&#39;starprefer&#39;]&gt;&#x3D;60):</span><br><span class="line">            x[&#39;consuming_capacity&#39;] &#x3D; fill2</span><br><span class="line">        else:</span><br><span class="line">            x[&#39;consuming_capacity&#39;] &#x3D; fill3</span><br><span class="line">    else:</span><br><span class="line">        return x</span><br><span class="line">    return x</span><br><span class="line">df[[&#39;consuming_capacity&#39;,&#39;starprefer&#39;]] &#x3D; df[[&#39;consuming_capacity&#39;,&#39;starprefer&#39;]].apply(fill_consuming_capacity,axis&#x3D;1)</span><br></pre></td></tr></table></figure>
<h5 id="2-1-3-4-用其他字段聚类填充"><a href="#2-1-3-4-用其他字段聚类填充" class="headerlink" title="2.1.3.4 用其他字段聚类填充"></a>2.1.3.4 用其他字段聚类填充</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df_corr[&#39;commentnums&#39;].sort_values(ascending&#x3D;False)[[0,1,2,3]]</span><br><span class="line">Out[18]: </span><br><span class="line">commentnums    1.000000</span><br><span class="line">novoters       0.992748</span><br><span class="line">cancelrate     0.870245</span><br><span class="line">hoteluv        0.662154</span><br><span class="line">Name: commentnums, dtype: float64</span><br></pre></td></tr></table></figure>
<p>可看到commentnums和novoters、cancelrate、hoteluv存在较强相关性，可通过聚类取中位数的方式来填充commentnums。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 聚类填充commentnums</span></span><br><span class="line"><span class="comment">#commentnums：当前酒店点评数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">km = KMeans(n_clusters=<span class="number">4</span>)</span><br><span class="line">data = df.loc[:,[<span class="string">&#x27;commentnums&#x27;</span>,<span class="string">&#x27;novoters&#x27;</span>,<span class="string">&#x27;cancelrate&#x27;</span>,<span class="string">&#x27;hoteluv&#x27;</span>]]</span><br><span class="line">ss = StandardScaler()  <span class="comment"># 聚类算距离，需要先标准化</span></span><br><span class="line">data[[<span class="string">&#x27;novoters&#x27;</span>,<span class="string">&#x27;cancelrate&#x27;</span>,<span class="string">&#x27;hoteluv&#x27;</span>]] = pd.DataFrame(ss.fit_transform(data[[<span class="string">&#x27;novoters&#x27;</span>,<span class="string">&#x27;cancelrate&#x27;</span>,<span class="string">&#x27;hoteluv&#x27;</span>]]))</span><br><span class="line"></span><br><span class="line">km.fit(data.iloc[:,<span class="number">1</span>:])</span><br><span class="line">label_pred = km.labels_</span><br><span class="line">data[<span class="string">&#x27;label_pred&#x27;</span>] = label_pred</span><br><span class="line"><span class="comment">#metrics.calinski_harabaz_score(data.iloc[:,1:],km.labels_)</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;commentnums&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">0</span>),[<span class="string">&#x27;commentnums&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">0</span>,<span class="string">&#x27;commentnums&#x27;</span>]).median()</span><br><span class="line">data.loc[(data[<span class="string">&#x27;commentnums&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">1</span>),[<span class="string">&#x27;commentnums&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">1</span>,<span class="string">&#x27;commentnums&#x27;</span>]).median()</span><br><span class="line">data.loc[(data[<span class="string">&#x27;commentnums&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">2</span>),[<span class="string">&#x27;commentnums&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">2</span>,<span class="string">&#x27;commentnums&#x27;</span>]).median()</span><br><span class="line">data.loc[(data[<span class="string">&#x27;commentnums&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">3</span>),[<span class="string">&#x27;commentnums&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">3</span>,<span class="string">&#x27;commentnums&#x27;</span>]).median()</span><br><span class="line">df[<span class="string">&#x27;commentnums&#x27;</span>] = data[<span class="string">&#x27;commentnums&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>同理，取starprefer和consuming_capacity聚类后每类avgprice的均值来填充avgprice的空值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#avgprice：starprefer,consuming_capacity</span></span><br><span class="line">km = KMeans(n_clusters=<span class="number">5</span>)</span><br><span class="line">data = df.loc[:,[<span class="string">&#x27;avgprice&#x27;</span>,<span class="string">&#x27;starprefer&#x27;</span>,<span class="string">&#x27;consuming_capacity&#x27;</span>]]</span><br><span class="line">ss = StandardScaler()  <span class="comment"># 聚类算距离，需要先标准化</span></span><br><span class="line">data[[<span class="string">&#x27;starprefer&#x27;</span>,<span class="string">&#x27;consuming_capacity&#x27;</span>]] = pd.DataFrame(ss.fit_transform(data[[<span class="string">&#x27;starprefer&#x27;</span>,<span class="string">&#x27;consuming_capacity&#x27;</span>]]))</span><br><span class="line">km.fit(data.iloc[:,<span class="number">1</span>:])</span><br><span class="line">label_pred = km.labels_</span><br><span class="line">data[<span class="string">&#x27;label_pred&#x27;</span>] = label_pred</span><br><span class="line"><span class="comment">#metrics.calinski_harabaz_score(data.iloc[:,1:],km.labels_)</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;avgprice&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">0</span>),[<span class="string">&#x27;avgprice&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">0</span>,<span class="string">&#x27;avgprice&#x27;</span>]).mean()</span><br><span class="line">data.loc[(data[<span class="string">&#x27;avgprice&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">1</span>),[<span class="string">&#x27;avgprice&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">1</span>,<span class="string">&#x27;avgprice&#x27;</span>]).mean()</span><br><span class="line">data.loc[(data[<span class="string">&#x27;avgprice&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">2</span>),[<span class="string">&#x27;avgprice&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">2</span>,<span class="string">&#x27;avgprice&#x27;</span>]).mean()</span><br><span class="line">data.loc[(data[<span class="string">&#x27;avgprice&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">3</span>),[<span class="string">&#x27;avgprice&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">3</span>,<span class="string">&#x27;avgprice&#x27;</span>]).mean()</span><br><span class="line">data.loc[(data[<span class="string">&#x27;avgprice&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">4</span>),[<span class="string">&#x27;avgprice&#x27;</span>]] = (data.loc[data[<span class="string">&#x27;label_pred&#x27;</span>] == <span class="number">4</span>,<span class="string">&#x27;avgprice&#x27;</span>]).mean()</span><br><span class="line">df[<span class="string">&#x27;avgprice&#x27;</span>] = data[<span class="string">&#x27;avgprice&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>取consuming_capacity和avgprice聚类后的中位数来填充delta_price1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#delta_price1：consuming_capacity,avgprice</span></span><br><span class="line">km = KMeans(n_clusters=<span class="number">6</span>)</span><br><span class="line">data = df.loc[:,[<span class="string">&#x27;delta_price1&#x27;</span>,<span class="string">&#x27;consuming_capacity&#x27;</span>,<span class="string">&#x27;avgprice&#x27;</span>]]</span><br><span class="line">ss = StandardScaler()  <span class="comment"># 聚类算距离，需要先标准化</span></span><br><span class="line">data[[<span class="string">&#x27;consuming_capacity&#x27;</span>,<span class="string">&#x27;avgprice&#x27;</span>]] = pd.DataFrame(ss.fit_transform(data[[<span class="string">&#x27;consuming_capacity&#x27;</span>,<span class="string">&#x27;avgprice&#x27;</span>]]))</span><br><span class="line"></span><br><span class="line">km.fit(data.iloc[:,<span class="number">1</span>:])</span><br><span class="line">label_pred = km.labels_</span><br><span class="line">data[<span class="string">&#x27;label_pred&#x27;</span>] = label_pred</span><br><span class="line"><span class="comment">#metrics.calinski_harabaz_score(data.iloc[:,1:],km.labels_)</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;delta_price1&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">0</span>),[<span class="string">&#x27;delta_price1&#x27;</span>]] = <span class="number">187</span><span class="comment">#data[&#x27;fill0&#x27;]</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;delta_price1&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">1</span>),[<span class="string">&#x27;delta_price1&#x27;</span>]] = <span class="number">100</span><span class="comment">#data[&#x27;fill1&#x27;]</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;delta_price1&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">2</span>),[<span class="string">&#x27;delta_price1&#x27;</span>]] = <span class="number">26</span><span class="comment">#data[&#x27;fill2&#x27;]</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;delta_price1&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">3</span>),[<span class="string">&#x27;delta_price1&#x27;</span>]] = <span class="number">1269</span><span class="comment">#data[&#x27;fill0&#x27;]</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;delta_price1&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">4</span>),[<span class="string">&#x27;delta_price1&#x27;</span>]] = <span class="number">323</span><span class="comment">#data[&#x27;fill0&#x27;]</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;delta_price1&#x27;</span>].isnull())&amp;(data[<span class="string">&#x27;label_pred&#x27;</span>]==<span class="number">5</span>),[<span class="string">&#x27;delta_price1&#x27;</span>]] = <span class="number">573</span><span class="comment">#data[&#x27;fill0&#x27;]</span></span><br><span class="line">df[<span class="string">&#x27;delta_price1&#x27;</span>] = data[<span class="string">&#x27;delta_price1&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>缺失值处理完毕。</p>
<h3 id="2-2-分析指标"><a href="#2-2-分析指标" class="headerlink" title="2.2 分析指标"></a>2.2 分析指标</h3><h4 id="2-2-1-客户分析"><a href="#2-2-1-客户分析" class="headerlink" title="2.2.1 客户分析"></a>2.2.1 客户分析</h4><p><strong>1、星级分布</strong></p>
<img src="../images/5.jpg" style="zoom:50%;" />

<p>大部分客户的星级偏好在[40，100]，并且有相当多的客户的星级偏好集中在40,60,80,100左右。</p>
<p><strong>2、客户价值分布</strong></p>
<img src="../images/6.jpg" style="zoom:50%;" />

<p>客户价值主要小于10，低价值客户占比较大。</p>
<p><strong>3、价格敏感指数分布</strong></p>
<img src="../images/7.jpg" style="zoom:50%;" />

<p>极值出现在数据两端， 大部分人对价格变动并不敏感，价格敏感指数为100时的人数也并不少，针对这一部分客户，可以考虑用一些打折优惠的方式吸引消费。</p>
<p><strong>4、客户消费能力指数</strong></p>
<img src="../images/8.jpg" style="zoom:50%;" />

<p>客户消费能力指数集中在[10，50]，其中在34左右的人群最多， 说明大部分消费人群消费能力中等，还有部分人群消费能力指数在接近100，属于高消费能力人群。</p>
<p><strong>5、访问时间点分布</strong></p>
<img src="../images/9.jpg" style="zoom:50%;" />

<p>凌晨1点到7点访问人数较少，在晚上10点访问最多，这一分布符合人们的入住习惯。</p>
<p><strong>6、新老客户占比及流失率</strong></p>
<img src="../images/10.jpg" style="zoom:50%;" />



<ul>
<li><p>94.42%的客户是老客户,新访客户仅占5.58%， 老客户是酒店客源的中坚力量</p>
</li>
<li><p>老客的流失率达到28%，新客的流失率占20%（与数量占比有关）， 需应该采取措施，谨防客户流失</p>
</li>
</ul>
<p><strong>7、用户订单数分布，预定和入住人数</strong></p>
<img src="../images/11.jpg" style="zoom:50%;" />

<img src="../images/12.jpg" style="zoom:50%;" />

<p>酒店的访问和入住人数在5月20日这一天达到峰值，是因为由于5月20日对于情侣有特殊的意义， 后续的酒店的入住人数有两个小高峰，对应的日期是周末的时间。</p>
<h4 id="2-2-2-酒店分析"><a href="#2-2-2-酒店分析" class="headerlink" title="2.2.2 酒店分析"></a>2.2.2 酒店分析</h4><p><strong>1、酒店价格分布</strong></p>
<img src="../images/13.jpg" style="zoom:50%;" />

<p>在客户选择的酒店里，大部分酒店的价格在1000元以内，100到400元价格区间内的数量最多，与客户消费能力指数趋势一致。</p>
<p><strong>2、酒店商务指数</strong></p>
<p>酒店商务指数分布图</p>
<img src="../images/14.png" style="zoom:80%;" />

<p>依据分布的分箱图</p>
<img src="../images/15.png" style="zoom:67%;" />

<ul>
<li>指数0.4以下:低</li>
<li>指数0.4~0.6:中</li>
<li>指数0.6~0.8:较高</li>
<li>指数0.8以上:高</li>
</ul>
<p>24小时<strong>已访问</strong>和<strong>浏览最多</strong>酒店,商务指数小于0.6(总指数为1), 占比超80%，考虑到商务性指数与价格相关度高，而大多数人的预期价格都比较低，所以商务型指数也不高。</p>
<h3 id="2-3-特征工程"><a href="#2-3-特征工程" class="headerlink" title="2.3 特征工程"></a>2.3 特征工程</h3><h4 id="2-3-1-新增字段"><a href="#2-3-1-新增字段" class="headerlink" title="2.3.1 新增字段"></a>2.3.1 新增字段</h4><ul>
<li>时间字段<br>新增字段：访问日期和入住日期间隔天数booking_gap、入住日期是星期几week_day、入住日期是否是周末is_weekend</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#格式为年-月-日</span></span><br><span class="line">df[[<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;arrival&#x27;</span>]] = df[[<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;arrival&#x27;</span>]].apply(<span class="keyword">lambda</span> x:pd.to_datetime(x,<span class="built_in">format</span>=<span class="string">&#x27;%Y-%m-%d&#x27;</span>))</span><br><span class="line"><span class="comment">#访问日期和入住日期间隔天数</span></span><br><span class="line">df[<span class="string">&#x27;booking_gap&#x27;</span>] = ((df[<span class="string">&#x27;arrival&#x27;</span>]-df[<span class="string">&#x27;d&#x27;</span>])/np.timedelta64(<span class="number">1</span>,<span class="string">&#x27;D&#x27;</span>)).astype(<span class="built_in">int</span>)</span><br><span class="line"><span class="comment">#入住日期是星期几</span></span><br><span class="line">df[<span class="string">&#x27;week_day&#x27;</span>] = df[<span class="string">&#x27;arrival&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.weekday())</span><br><span class="line"><span class="comment">#入住日期是否是周末</span></span><br><span class="line">df[<span class="string">&#x27;is_weekend&#x27;</span>] = df[<span class="string">&#x27;week_day&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x <span class="keyword">in</span> (<span class="number">5</span>,<span class="number">6</span>) <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>是否是同一个样本【选取部分客户行为指标】<br>查看字段sid，发现95%都是老用户，新用户很少，一周内部分用户可能会下多个订单，为了<strong>方便后续划分训练集和验证集</strong>，避免使用其他用户的数据来预测一个用户。此处添加一个user_tag来区分是否是同一个用户的订单。</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;user_tag&#x27;</span>] = df[<span class="string">&#x27;ordercanceledprecent&#x27;</span>].<span class="keyword">map</span>(str) + df[<span class="string">&#x27;ordercanncelednum&#x27;</span>].<span class="keyword">map</span>(str) + df[<span class="string">&#x27;ordernum_oneyear&#x27;</span>].<span class="keyword">map</span>(str) +\</span><br><span class="line">                  df[<span class="string">&#x27;starprefer&#x27;</span>].<span class="keyword">map</span>(str) + df[<span class="string">&#x27;consuming_capacity&#x27;</span>].<span class="keyword">map</span>(str) + \</span><br><span class="line">                 df[<span class="string">&#x27;price_sensitive&#x27;</span>].<span class="keyword">map</span>(str) + df[<span class="string">&#x27;customer_value_profit&#x27;</span>].<span class="keyword">map</span>(str) + df[<span class="string">&#x27;ctrip_profits&#x27;</span>].<span class="keyword">map</span>(str) +df[<span class="string">&#x27;visitnum_oneyear&#x27;</span>].<span class="keyword">map</span>(str) + \</span><br><span class="line">                  df[<span class="string">&#x27;historyvisit_avghotelnum&#x27;</span>].<span class="keyword">map</span>(str) + df[<span class="string">&#x27;businessrate_pre2&#x27;</span>].<span class="keyword">map</span>(str) +\</span><br><span class="line">                df[<span class="string">&#x27;historyvisit_visit_detailpagenum&#x27;</span>].<span class="keyword">map</span>(str) + \</span><br><span class="line">                  df[<span class="string">&#x27;delta_price2&#x27;</span>].<span class="keyword">map</span>(str) +  \</span><br><span class="line">                df[<span class="string">&#x27;commentnums_pre2&#x27;</span>].<span class="keyword">map</span>(str) + df[<span class="string">&#x27;novoters_pre2&#x27;</span>].<span class="keyword">map</span>(str) +df[<span class="string">&#x27;customereval_pre2&#x27;</span>].<span class="keyword">map</span>(str) + df[<span class="string">&#x27;lowestprice_pre2&#x27;</span>].<span class="keyword">map</span>(str)</span><br><span class="line">df[<span class="string">&#x27;user_tag&#x27;</span>] = df[<span class="string">&#x27;user_tag&#x27;</span>].apply(lambda x : hash(x))</span><br><span class="line">df[<span class="string">&#x27;user_tag&#x27;</span>].unique().shape</span><br></pre></td></tr></table></figure>
<p>返回670226，即实际这周有670226个用户下过订单。</p>
<ul>
<li>用户字段和酒店字段<br>选取部分用户相关字段进行聚类创建用户字段user_group，选取部分酒店相关字段进行聚类创建酒店字段hotel_group。</li>
</ul>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">user_group = [<span class="string">&#x27;ordercanceledprecent&#x27;</span>,<span class="string">&#x27;ordercanncelednum&#x27;</span>,<span class="string">&#x27;ordernum_oneyear&#x27;</span>,</span><br><span class="line">             <span class="string">&#x27;historyvisit_visit_detailpagenum&#x27;</span>,<span class="string">&#x27;historyvisit_avghotelnum&#x27;</span>]</span><br><span class="line">hotel_group = [<span class="string">&#x27;commentnums&#x27;</span>, <span class="string">&#x27;novoters&#x27;</span>, <span class="string">&#x27;lowestprice&#x27;</span>, <span class="string">&#x27;hotelcr&#x27;</span>, <span class="string">&#x27;hoteluv&#x27;</span>, <span class="string">&#x27;cancelrate&#x27;</span>]</span><br><span class="line"><span class="meta">#聚类之前先标准化</span></span><br><span class="line">km_user = pd.DataFrame(df[user_group])</span><br><span class="line">km_hotel = pd.DataFrame(df[hotel_group])</span><br><span class="line">ss = StandardScaler()</span><br><span class="line"><span class="function"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="title">range</span>(<span class="params">km_user.shape[<span class="number">1</span>]</span>):</span></span><br><span class="line"><span class="function">    km_user[user_group[i]]</span> = ss.fit_transform(df[user_group[i]].values.reshape(<span class="number">-1</span>, <span class="number">1</span>)).ravel()</span><br><span class="line">ss = StandardScaler()</span><br><span class="line"><span class="function"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="title">range</span>(<span class="params">km_hotel.shape[<span class="number">1</span>]</span>):</span></span><br><span class="line"><span class="function">    km_hotel[hotel_group[i]]</span> = ss.fit_transform(df[hotel_group[i]].values.reshape(<span class="number">-1</span>, <span class="number">1</span>)).ravel()</span><br><span class="line">df[<span class="string">&#x27;user_group&#x27;</span>] = KMeans(n_clusters=<span class="number">3</span>).fit_predict(km_user)</span><br><span class="line"><span class="meta"># score = metrics.calinski_harabaz_score(km_user,KMeans(n_clusters=3).fit(km_user).labels_)</span></span><br><span class="line"><span class="meta"># print(&#x27;数据聚calinski_harabaz指数为：%f&#x27;%(score)) #3:218580.269018  4:218580.416497 5:218581.368953 6:218581.203569 </span></span><br><span class="line">df[<span class="string">&#x27;hotel_group&#x27;</span>] = KMeans(n_clusters=<span class="number">5</span>).fit_predict(km_hotel)</span><br><span class="line"><span class="meta"># score = metrics.calinski_harabaz_score(km_hotel,KMeans(n_clusters=3).fit(km_hotel).labels_)</span></span><br><span class="line"><span class="meta"># print(&#x27;数据聚calinski_harabaz指数为：%f&#x27;%(score))  #3：266853.481135  4:268442.314369 5:268796.468103 6:268796.707149</span></span><br></pre></td></tr></table></figure>
<h4 id="2-3-2-连续特征离散化"><a href="#2-3-2-连续特征离散化" class="headerlink" title="2.3.2 连续特征离散化"></a>2.3.2 连续特征离散化</h4><p>historyvisit_avghotelnum大部分都小于5，将字段处理成小于等于5和大于5的离散值；<br>ordercanncelednum大部分都小于5，将字段处理成小于等于5和大于5的离散值；<br>sid等于1是新访设为0，其他设为1为老用户。<br>avgprice、lowestprice、starprefer、consuming_capacity和h进行数值分段离散化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;historyvisit_avghotelnum&#x27;</span>] = df[<span class="string">&#x27;historyvisit_avghotelnum&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x&lt;=<span class="number">5</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line">df[<span class="string">&#x27;ordercanncelednum&#x27;</span>] = df[<span class="string">&#x27;ordercanncelednum&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x&lt;=<span class="number">5</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line">df[<span class="string">&#x27;sid&#x27;</span>] = df[<span class="string">&#x27;sid&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x==<span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span>)  </span><br><span class="line"><span class="comment">#分段离散化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discrete_avgprice</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x&lt;=<span class="number">200</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">400</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">600</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discrete_lowestprice</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x&lt;=<span class="number">100</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">200</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">300</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discrete_starprefer</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">60</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">80</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discrete_consuming_capacity</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x&lt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">20</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">40</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;=<span class="number">60</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">4</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discrete_h</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x&gt;=<span class="number">0</span> <span class="keyword">and</span> x&lt;<span class="number">6</span>:<span class="comment">#凌晨访问</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;<span class="number">12</span>:<span class="comment">#上午访问</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> x&lt;<span class="number">18</span>:<span class="comment">#下午访问</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">3</span><span class="comment">#晚上访问</span></span><br><span class="line">    </span><br><span class="line">df[<span class="string">&#x27;avgprice&#x27;</span>] = df[<span class="string">&#x27;avgprice&#x27;</span>].<span class="built_in">map</span>(discrete_avgprice)</span><br><span class="line">df[<span class="string">&#x27;lowestprice&#x27;</span>] = df[<span class="string">&#x27;lowestprice&#x27;</span>].<span class="built_in">map</span>(discrete_lowestprice)</span><br><span class="line">df[<span class="string">&#x27;starprefer&#x27;</span>] = df[<span class="string">&#x27;starprefer&#x27;</span>].<span class="built_in">map</span>(discrete_starprefer)</span><br><span class="line">df[<span class="string">&#x27;consuming_capacity&#x27;</span>] = df[<span class="string">&#x27;consuming_capacity&#x27;</span>].<span class="built_in">map</span>(discrete_consuming_capacity)</span><br><span class="line">df[<span class="string">&#x27;h&#x27;</span>] = df[<span class="string">&#x27;h&#x27;</span>].<span class="built_in">map</span>(discrete_h)</span><br></pre></td></tr></table></figure>
<p>对当前的数值型类别变量（定型特征）进行定性特征热编码（转化为定量特征），此处用OneHotEncoder方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">discrete_field = [<span class="string">&#x27;historyvisit_avghotelnum&#x27;</span>,<span class="string">&#x27;ordercanncelednum&#x27;</span></span><br><span class="line">                  ,<span class="string">&#x27;avgprice&#x27;</span>,<span class="string">&#x27;lowestprice&#x27;</span>,<span class="string">&#x27;starprefer&#x27;</span>,<span class="string">&#x27;consuming_capacity&#x27;</span>,<span class="string">&#x27;user_group&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;hotel_group&#x27;</span>,<span class="string">&#x27;is_weekend&#x27;</span>,<span class="string">&#x27;week_day&#x27;</span>,<span class="string">&#x27;sid&#x27;</span>,<span class="string">&#x27;h&#x27;</span>]</span><br><span class="line">encode_df = pd.DataFrame(preprocessing.OneHotEncoder(handle_unknown=<span class="string">&#x27;ignore&#x27;</span>).fit_transform(df[discrete_field]).toarray())</span><br><span class="line">encode_df_new = pd.concat([df.drop(columns=discrete_field,axis=<span class="number">1</span>),encode_df],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-3-3-删除字段"><a href="#2-3-3-删除字段" class="headerlink" title="2.3.3 删除字段"></a>2.3.3 删除字段</h4><p>去掉两类字段：<br>d、arrival、sampleid、firstorder_bu字段；<br>historyvisit_totalordernum和ordernum_oneyear这两个字段值相等，此处取ordernum_oneyear这个字段，删除historyvisit_totalordernum；<br>decisionhabit_user和historyvisit_avghotelnum数值较一致，此处选择historyvisit_avghotelnum，删除decisionhabit_user。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">encode_df_new = encode_df_new.<span class="built_in">drop</span>(columns=[<span class="string">&#x27;d&#x27;</span>,<span class="symbol">&#x27;arrival</span><span class="string">&#x27;,&#x27;</span>sampleid<span class="string">&#x27;,&#x27;</span>historyvisit_totalordernum<span class="string">&#x27;,&#x27;</span>firstorder_bu<span class="string">&#x27;,&#x27;</span>decisionhabit_user&#x27;],axis=<span class="number">1</span>)</span><br><span class="line">encode_df_new.shape</span><br></pre></td></tr></table></figure>
<p>最终去除目标字段label和划分训练集字段user_tag，共有79个字段。</p>
<h3 id="2-3-模型训练"><a href="#2-3-模型训练" class="headerlink" title="2.3 模型训练"></a>2.3 模型训练</h3><h4 id="2-3-1-划分训练集和验证集"><a href="#2-3-1-划分训练集和验证集" class="headerlink" title="2.3.1 划分训练集和验证集"></a>2.3.1 划分训练集和验证集</h4><p>为了保证训练集和验证集独立同分布，将数据按照user_tag进行排序，取前70%作为训练集，剩余的作为验证集。</p>
<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line">ss_df_new = encode_df_new</span><br><span class="line"><span class="built_in">num</span> = ss_df_new.shape[<span class="number">0</span>]</span><br><span class="line">df_sort = ss_df_new.sort_values(by=[<span class="string">&#x27;user_tag&#x27;</span>],ascending=True)</span><br><span class="line">train_df = df_sort.iloc[:<span class="built_in">int</span>(<span class="built_in">num</span>*<span class="number">0.7</span>),:]</span><br><span class="line">test_df = df_sort.iloc[<span class="built_in">int</span>(<span class="built_in">num</span>*<span class="number">0.7</span>):,:]</span><br><span class="line">train_y = train_df[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">train_x = train_df.iloc[:,<span class="number">1</span>:]</span><br><span class="line">test_y = test_df[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">test_x = test_df.iloc[:,<span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
<h4 id="2-3-2-比较各个模型的训练效果"><a href="#2-3-2-比较各个模型的训练效果" class="headerlink" title="2.3.2 比较各个模型的训练效果"></a>2.3.2 比较各个模型的训练效果</h4><p>所有模型的调参都采用GridSearchCV网格搜索进行。</p>
<ul>
<li>xgboost</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#调整的参数：</span></span><br><span class="line"><span class="comment">#迭代器个数n_estimators</span></span><br><span class="line"><span class="comment">#min_child_weight以及max_depth</span></span><br><span class="line"><span class="comment">#gamma值</span></span><br><span class="line"><span class="comment">##subsample 和 colsample_bytree</span></span><br><span class="line"><span class="comment">#learning_rate，需要配合调整n_esgtimators</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> xgboost.sklearn <span class="keyword">import</span> XGBClassifier</span><br><span class="line">xgbc = XGBClassifier(learning_rate=<span class="number">0.05</span>, objective= <span class="string">&#x27;binary:logistic&#x27;</span>, nthread=<span class="number">1</span>,  scale_pos_weight=<span class="number">1</span>, seed=<span class="number">27</span>,</span><br><span class="line">                    subsample=<span class="number">0.6</span>, colsample_bytree=<span class="number">0.6</span>, gamma=<span class="number">0</span>, reg_alpha= <span class="number">0</span>, reg_lambda=<span class="number">1</span>,max_depth=<span class="number">38</span>,min_child_weight=<span class="number">1</span>,n_estimators=<span class="number">210</span>)</span><br><span class="line">xgbc.fit(train_x,train_y)</span><br><span class="line">predict_train = xgbc.predict_proba(train_x)[:,<span class="number">1</span>]</span><br><span class="line">predict_test = xgbc.predict_proba(test_x)[:,<span class="number">1</span>]</span><br><span class="line">pr_train,re_train,thre_train = metrics.precision_recall_curve(train_y,predict_train)</span><br><span class="line">pr_test,re_test,thre_test = metrics.precision_recall_curve(test_y,predict_test)</span><br><span class="line">auc_train = metrics.roc_auc_score(train_y,predict_train)</span><br><span class="line">auc_test = metrics.roc_auc_score(test_y,predict_test)</span><br><span class="line">prt_train = pd.DataFrame(&#123;<span class="string">&#x27;precision&#x27;</span>:pr_train,<span class="string">&#x27;recall&#x27;</span>:re_train&#125;)</span><br><span class="line">prt_test = pd.DataFrame(&#123;<span class="string">&#x27;precision&#x27;</span>:pr_test,<span class="string">&#x27;recall&#x27;</span>:re_test&#125;)</span><br><span class="line">print(<span class="string">&#x27;precision&gt;=0.97时对应的最大recall为：&#x27;</span>)</span><br><span class="line">print(prt_test.loc[prt_test[<span class="string">&#x27;precision&#x27;</span>]&gt;=<span class="number">0.97</span>,<span class="string">&#x27;recall&#x27;</span>].<span class="built_in">max</span>())</span><br><span class="line">print(<span class="string">&#x27;auc得分为：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(auc_test))</span><br></pre></td></tr></table></figure>
<p>precision&gt;=0.97时对应的最大recall为：<br>0.7435550716493396<br>auc得分为：0.9730951405840338）</p>
<ul>
<li>随机森林</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#调整的参数：</span></span><br><span class="line"><span class="comment">#n_estimators</span></span><br><span class="line"><span class="comment">#max_depth</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">rf = RandomForestClassifier(n_estimators=<span class="number">300</span>,max_depth=<span class="number">50</span>)</span><br><span class="line">rf.fit(train_x,train_y)</span><br><span class="line">predict_train = rf.predict_proba(train_x)[:,<span class="number">1</span>]</span><br><span class="line">predict_test = rf.predict_proba(test_x)[:,<span class="number">1</span>]</span><br><span class="line">pr_train,re_train,thre_train = metrics.precision_recall_curve(train_y,predict_train)</span><br><span class="line">pr_test,re_test,thre_test = metrics.precision_recall_curve(test_y,predict_test)</span><br><span class="line">auc_train = metrics.roc_auc_score(train_y,predict_train)</span><br><span class="line">auc_test = metrics.roc_auc_score(test_y,predict_test)</span><br><span class="line">prt_train = pd.DataFrame(&#123;<span class="string">&#x27;precision&#x27;</span>:pr_train,<span class="string">&#x27;recall&#x27;</span>:re_train&#125;)</span><br><span class="line">prt_test = pd.DataFrame(&#123;<span class="string">&#x27;precision&#x27;</span>:pr_test,<span class="string">&#x27;recall&#x27;</span>:re_test&#125;)</span><br><span class="line">print(<span class="string">&#x27;precision&gt;=0.97时对应的最大recall为：&#x27;</span>)</span><br><span class="line">print(prt_test.loc[prt_test[<span class="string">&#x27;precision&#x27;</span>]&gt;=<span class="number">0.97</span>,<span class="string">&#x27;recall&#x27;</span>].<span class="built_in">max</span>())</span><br><span class="line">print(<span class="string">&#x27;auc得分为：&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(auc_test))</span><br></pre></td></tr></table></figure>
<p>precision&gt;=0.97时对应的最大recall为：<br>0.6566275639224501<br>auc得分为：0.9616994012330063</p>
<p>根据上述结果可知，xgboost的训练效果最好，当precision&gt;=0.97时，recall最大能达到74.4%。</p>
<h4 id="2-3-3-重要特征"><a href="#2-3-3-重要特征" class="headerlink" title="2.3.3 重要特征"></a>2.3.3 重要特征</h4><p>使用XGBoost. plot_importance</p>
<img src="../images/18.png"  />

<p>部分重要特征解释：</p>
<table>
<thead>
<tr>
<th><strong>特征</strong></th>
<th><strong>解释</strong></th>
<th>维度</th>
<th>分析</th>
</tr>
</thead>
<tbody><tr>
<td>lastpvgap</td>
<td>一年内距上次访问时长</td>
<td>用户</td>
<td>用户是否活跃</td>
</tr>
<tr>
<td>visitnum_oneyear</td>
<td>年访问次数</td>
<td>用户</td>
<td>用户是否活跃</td>
</tr>
<tr>
<td>cityuvs</td>
<td>昨日访问当前城市同入住日期的app  uv数</td>
<td>用户</td>
<td>用户是否流失到别的平台</td>
</tr>
<tr>
<td>sid</td>
<td>会话id，sid=1可认为是新访</td>
<td>用户</td>
<td>新老用户</td>
</tr>
<tr>
<td>lasthtlordergap</td>
<td>一年内距离上次下单时长</td>
<td>订单</td>
<td>用户是否活跃</td>
</tr>
<tr>
<td>ctrip_profits</td>
<td>客户价值</td>
<td>用户</td>
<td>用户价值越高越不容易流失，反之亦然</td>
</tr>
<tr>
<td>uv_pre</td>
<td>24小时历史浏览次数最多酒店历史uv</td>
<td>酒店</td>
<td>用户偏好的酒店的热度</td>
</tr>
<tr>
<td>h</td>
<td>访问时间点</td>
<td>订单</td>
<td>用户是否活跃</td>
</tr>
<tr>
<td>lowestprice_pre</td>
<td>24小时内已访问次数最多酒店可订最低价</td>
<td>酒店</td>
<td>用户偏好的酒店价格</td>
</tr>
<tr>
<td>jd_people_max</td>
<td>酒店点评浏览</td>
<td>酒店</td>
<td>对于预订网站，<strong>评价</strong>是影响用户做决定的重要因素</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>个人项目</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
</search>
